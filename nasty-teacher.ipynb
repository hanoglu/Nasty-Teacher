{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":93996,"status":"ok","timestamp":1718025815597,"user":{"displayName":"bilge gunsel","userId":"10924216968931407832"},"user_tz":-180},"id":"d3R158wqtp8_","outputId":"e8de0245-6a05-4663-be9c-00675667df09"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"58DXC1PavDLz"},"outputs":[],"source":["%cd /project-root"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"9zOona9Pw4bu","outputId":"99ce1f2c-a0e3-43d0-f13f-00b9bff016cb"},"outputs":[{"name":"stdout","output_type":"stream","text":["model_name:resnet18\n","learning_rate:0.1\n","schedule:[80, 120]\n","gamma:0.1\n","batch_size:128\n","num_epochs:160\n","num_workers:4\n","augmentation:1\n","cuda:True\n","dataset:cifar10\n","Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/data-cifar10/cifar-10-python.tar.gz\n","100% 170498071/170498071 [00:13<00:00, 12649883.17it/s]\n","Extracting ./data/data-cifar10/cifar-10-python.tar.gz to ./data/data-cifar10\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Number of class: 10\n","Create Model --- resnet18\n","- Train from scratch \n","Optimizer: SGD\n","Epoch 1/160\n","Learning Rate 0.1\n","100% 391/391 [00:19<00:00, 19.70it/s, loss=1.883]\n","- Train loss : 1.883\n","- Eval metrics : acc: 40.101 ; loss: 1.618\n","- New best model \n","- So far best epoch: 1, best acc: 40.101\n","Epoch 2/160\n","Learning Rate 0.1\n","100% 391/391 [00:17<00:00, 22.00it/s, loss=1.429]\n","- Train loss : 1.429\n","- Eval metrics : acc: 50.574 ; loss: 1.374\n","- New best model \n","- So far best epoch: 2, best acc: 50.574\n","Epoch 3/160\n","Learning Rate 0.1\n","100% 391/391 [00:17<00:00, 21.76it/s, loss=1.198]\n","- Train loss : 1.198\n","- Eval metrics : acc: 58.238 ; loss: 1.197\n","- New best model \n","- So far best epoch: 3, best acc: 58.238\n","Epoch 4/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.61it/s, loss=1.000]\n","- Train loss : 1.000\n","- Eval metrics : acc: 65.635 ; loss: 0.974\n","- New best model \n","- So far best epoch: 4, best acc: 65.635\n","Epoch 5/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.41it/s, loss=0.850]\n","- Train loss : 0.850\n","- Eval metrics : acc: 64.715 ; loss: 1.079\n","- So far best epoch: 4, best acc: 65.635\n","Epoch 6/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.25it/s, loss=0.706]\n","- Train loss : 0.706\n","- Eval metrics : acc: 74.654 ; loss: 0.729\n","- New best model \n","- So far best epoch: 6, best acc: 74.654\n","Epoch 7/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.33it/s, loss=0.623]\n","- Train loss : 0.623\n","- Eval metrics : acc: 75.870 ; loss: 0.726\n","- New best model \n","- So far best epoch: 7, best acc: 75.870\n","Epoch 8/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.44it/s, loss=0.576]\n","- Train loss : 0.576\n","- Eval metrics : acc: 76.671 ; loss: 0.695\n","- New best model \n","- So far best epoch: 8, best acc: 76.671\n","Epoch 9/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.49it/s, loss=0.540]\n","- Train loss : 0.540\n","- Eval metrics : acc: 76.513 ; loss: 0.702\n","- So far best epoch: 8, best acc: 76.671\n","Epoch 10/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.41it/s, loss=0.516]\n","- Train loss : 0.516\n","- Eval metrics : acc: 76.869 ; loss: 0.701\n","- New best model \n","- So far best epoch: 10, best acc: 76.869\n","Epoch 11/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.44it/s, loss=0.490]\n","- Train loss : 0.490\n","- Eval metrics : acc: 76.206 ; loss: 0.731\n","- So far best epoch: 10, best acc: 76.869\n","Epoch 12/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.41it/s, loss=0.471]\n","- Train loss : 0.471\n","- Eval metrics : acc: 62.609 ; loss: 1.383\n","- So far best epoch: 10, best acc: 76.869\n","Epoch 13/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.46it/s, loss=0.461]\n","- Train loss : 0.461\n","- Eval metrics : acc: 79.252 ; loss: 0.631\n","- New best model \n","- So far best epoch: 13, best acc: 79.252\n","Epoch 14/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.50it/s, loss=0.453]\n","- Train loss : 0.453\n","- Eval metrics : acc: 80.934 ; loss: 0.553\n","- New best model \n","- So far best epoch: 14, best acc: 80.934\n","Epoch 15/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.50it/s, loss=0.434]\n","- Train loss : 0.434\n","- Eval metrics : acc: 78.886 ; loss: 0.623\n","- So far best epoch: 14, best acc: 80.934\n","Epoch 16/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.44it/s, loss=0.428]\n","- Train loss : 0.428\n","- Eval metrics : acc: 77.917 ; loss: 0.675\n","- So far best epoch: 14, best acc: 80.934\n","Epoch 17/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.40it/s, loss=0.415]\n","- Train loss : 0.415\n","- Eval metrics : acc: 81.873 ; loss: 0.550\n","- New best model \n","- So far best epoch: 17, best acc: 81.873\n","Epoch 18/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.42it/s, loss=0.407]\n","- Train loss : 0.407\n","- Eval metrics : acc: 82.536 ; loss: 0.542\n","- New best model \n","- So far best epoch: 18, best acc: 82.536\n","Epoch 19/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.51it/s, loss=0.404]\n","- Train loss : 0.404\n","- Eval metrics : acc: 80.083 ; loss: 0.592\n","- So far best epoch: 18, best acc: 82.536\n","Epoch 20/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.47it/s, loss=0.399]\n","- Train loss : 0.399\n","- Eval metrics : acc: 81.893 ; loss: 0.561\n","- So far best epoch: 18, best acc: 82.536\n","Epoch 21/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.43it/s, loss=0.391]\n","- Train loss : 0.391\n","- Eval metrics : acc: 82.239 ; loss: 0.534\n","- So far best epoch: 18, best acc: 82.536\n","Epoch 22/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.47it/s, loss=0.385]\n","- Train loss : 0.385\n","- Eval metrics : acc: 79.688 ; loss: 0.609\n","- So far best epoch: 18, best acc: 82.536\n","Epoch 23/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.45it/s, loss=0.383]\n","- Train loss : 0.383\n","- Eval metrics : acc: 83.317 ; loss: 0.495\n","- New best model \n","- So far best epoch: 23, best acc: 83.317\n","Epoch 24/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.46it/s, loss=0.377]\n","- Train loss : 0.377\n","- Eval metrics : acc: 81.448 ; loss: 0.555\n","- So far best epoch: 23, best acc: 83.317\n","Epoch 25/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.47it/s, loss=0.376]\n","- Train loss : 0.376\n","- Eval metrics : acc: 84.108 ; loss: 0.487\n","- New best model \n","- So far best epoch: 25, best acc: 84.108\n","Epoch 26/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.45it/s, loss=0.372]\n","- Train loss : 0.372\n","- Eval metrics : acc: 84.078 ; loss: 0.487\n","- So far best epoch: 25, best acc: 84.108\n","Epoch 27/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.49it/s, loss=0.364]\n","- Train loss : 0.364\n","- Eval metrics : acc: 81.507 ; loss: 0.565\n","- So far best epoch: 25, best acc: 84.108\n","Epoch 28/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.45it/s, loss=0.360]\n","- Train loss : 0.360\n","- Eval metrics : acc: 80.162 ; loss: 0.601\n","- So far best epoch: 25, best acc: 84.108\n","Epoch 29/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.49it/s, loss=0.364]\n","- Train loss : 0.364\n","- Eval metrics : acc: 81.655 ; loss: 0.561\n","- So far best epoch: 25, best acc: 84.108\n","Epoch 30/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.50it/s, loss=0.362]\n","- Train loss : 0.362\n","- Eval metrics : acc: 81.586 ; loss: 0.564\n","- So far best epoch: 25, best acc: 84.108\n","Epoch 31/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.54it/s, loss=0.358]\n","- Train loss : 0.358\n","- Eval metrics : acc: 85.038 ; loss: 0.469\n","- New best model \n","- So far best epoch: 31, best acc: 85.038\n","Epoch 32/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.48it/s, loss=0.357]\n","- Train loss : 0.357\n","- Eval metrics : acc: 82.278 ; loss: 0.530\n","- So far best epoch: 31, best acc: 85.038\n","Epoch 33/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.49it/s, loss=0.355]\n","- Train loss : 0.355\n","- Eval metrics : acc: 83.267 ; loss: 0.506\n","- So far best epoch: 31, best acc: 85.038\n","Epoch 34/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.46it/s, loss=0.351]\n","- Train loss : 0.351\n","- Eval metrics : acc: 81.903 ; loss: 0.577\n","- So far best epoch: 31, best acc: 85.038\n","Epoch 35/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.50it/s, loss=0.346]\n","- Train loss : 0.346\n","- Eval metrics : acc: 81.072 ; loss: 0.615\n","- So far best epoch: 31, best acc: 85.038\n","Epoch 36/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.46it/s, loss=0.347]\n","- Train loss : 0.347\n","- Eval metrics : acc: 83.604 ; loss: 0.506\n","- So far best epoch: 31, best acc: 85.038\n","Epoch 37/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.44it/s, loss=0.345]\n","- Train loss : 0.345\n","- Eval metrics : acc: 75.544 ; loss: 0.805\n","- So far best epoch: 31, best acc: 85.038\n","Epoch 38/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.49it/s, loss=0.347]\n","- Train loss : 0.347\n","- Eval metrics : acc: 83.950 ; loss: 0.494\n","- So far best epoch: 31, best acc: 85.038\n","Epoch 39/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.45it/s, loss=0.336]\n","- Train loss : 0.336\n","- Eval metrics : acc: 82.437 ; loss: 0.542\n","- So far best epoch: 31, best acc: 85.038\n","Epoch 40/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.48it/s, loss=0.339]\n","- Train loss : 0.339\n","- Eval metrics : acc: 80.004 ; loss: 0.637\n","- So far best epoch: 31, best acc: 85.038\n","Epoch 41/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.47it/s, loss=0.334]\n","- Train loss : 0.334\n","- Eval metrics : acc: 84.899 ; loss: 0.448\n","- So far best epoch: 31, best acc: 85.038\n","Epoch 42/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.45it/s, loss=0.337]\n","- Train loss : 0.337\n","- Eval metrics : acc: 82.674 ; loss: 0.543\n","- So far best epoch: 31, best acc: 85.038\n","Epoch 43/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.49it/s, loss=0.333]\n","- Train loss : 0.333\n","- Eval metrics : acc: 83.050 ; loss: 0.542\n","- So far best epoch: 31, best acc: 85.038\n","Epoch 44/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.50it/s, loss=0.331]\n","- Train loss : 0.331\n","- Eval metrics : acc: 80.518 ; loss: 0.630\n","- So far best epoch: 31, best acc: 85.038\n","Epoch 45/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.48it/s, loss=0.340]\n","- Train loss : 0.340\n","- Eval metrics : acc: 85.344 ; loss: 0.449\n","- New best model \n","- So far best epoch: 45, best acc: 85.344\n","Epoch 46/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.47it/s, loss=0.335]\n","- Train loss : 0.335\n","- Eval metrics : acc: 82.674 ; loss: 0.533\n","- So far best epoch: 45, best acc: 85.344\n","Epoch 47/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.48it/s, loss=0.333]\n","- Train loss : 0.333\n","- Eval metrics : acc: 82.783 ; loss: 0.521\n","- So far best epoch: 45, best acc: 85.344\n","Epoch 48/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.50it/s, loss=0.332]\n","- Train loss : 0.332\n","- Eval metrics : acc: 82.367 ; loss: 0.550\n","- So far best epoch: 45, best acc: 85.344\n","Epoch 49/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.49it/s, loss=0.328]\n","- Train loss : 0.328\n","- Eval metrics : acc: 85.107 ; loss: 0.460\n","- So far best epoch: 45, best acc: 85.344\n","Epoch 50/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.49it/s, loss=0.332]\n","- Train loss : 0.332\n","- Eval metrics : acc: 83.337 ; loss: 0.523\n","- So far best epoch: 45, best acc: 85.344\n","Epoch 51/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.49it/s, loss=0.332]\n","- Train loss : 0.332\n","- Eval metrics : acc: 84.761 ; loss: 0.478\n","- So far best epoch: 45, best acc: 85.344\n","Epoch 52/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.50it/s, loss=0.325]\n","- Train loss : 0.325\n","- Eval metrics : acc: 85.018 ; loss: 0.459\n","- So far best epoch: 45, best acc: 85.344\n","Epoch 53/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.48it/s, loss=0.326]\n","- Train loss : 0.326\n","- Eval metrics : acc: 82.486 ; loss: 0.546\n","- So far best epoch: 45, best acc: 85.344\n","Epoch 54/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.51it/s, loss=0.333]\n","- Train loss : 0.333\n","- Eval metrics : acc: 80.914 ; loss: 0.625\n","- So far best epoch: 45, best acc: 85.344\n","Epoch 55/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.53it/s, loss=0.325]\n","- Train loss : 0.325\n","- Eval metrics : acc: 86.679 ; loss: 0.398\n","- New best model \n","- So far best epoch: 55, best acc: 86.679\n","Epoch 56/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.50it/s, loss=0.324]\n","- Train loss : 0.324\n","- Eval metrics : acc: 84.593 ; loss: 0.475\n","- So far best epoch: 55, best acc: 86.679\n","Epoch 57/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.48it/s, loss=0.328]\n","- Train loss : 0.328\n","- Eval metrics : acc: 85.591 ; loss: 0.434\n","- So far best epoch: 55, best acc: 86.679\n","Epoch 58/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.49it/s, loss=0.326]\n","- Train loss : 0.326\n","- Eval metrics : acc: 81.972 ; loss: 0.573\n","- So far best epoch: 55, best acc: 86.679\n","Epoch 59/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.54it/s, loss=0.320]\n","- Train loss : 0.320\n","- Eval metrics : acc: 82.921 ; loss: 0.533\n","- So far best epoch: 55, best acc: 86.679\n","Epoch 60/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.50it/s, loss=0.326]\n","- Train loss : 0.326\n","- Eval metrics : acc: 82.229 ; loss: 0.572\n","- So far best epoch: 55, best acc: 86.679\n","Epoch 61/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.51it/s, loss=0.325]\n","- Train loss : 0.325\n","- Eval metrics : acc: 84.424 ; loss: 0.481\n","- So far best epoch: 55, best acc: 86.679\n","Epoch 62/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.51it/s, loss=0.322]\n","- Train loss : 0.322\n","- Eval metrics : acc: 85.839 ; loss: 0.415\n","- So far best epoch: 55, best acc: 86.679\n","Epoch 63/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.50it/s, loss=0.322]\n","- Train loss : 0.322\n","- Eval metrics : acc: 83.495 ; loss: 0.516\n","- So far best epoch: 55, best acc: 86.679\n","Epoch 64/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.51it/s, loss=0.325]\n","- Train loss : 0.325\n","- Eval metrics : acc: 81.023 ; loss: 0.611\n","- So far best epoch: 55, best acc: 86.679\n","Epoch 65/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.49it/s, loss=0.320]\n","- Train loss : 0.320\n","- Eval metrics : acc: 80.330 ; loss: 0.594\n","- So far best epoch: 55, best acc: 86.679\n","Epoch 66/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.51it/s, loss=0.316]\n","- Train loss : 0.316\n","- Eval metrics : acc: 81.695 ; loss: 0.558\n","- So far best epoch: 55, best acc: 86.679\n","Epoch 67/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.45it/s, loss=0.324]\n","- Train loss : 0.324\n","- Eval metrics : acc: 84.820 ; loss: 0.458\n","- So far best epoch: 55, best acc: 86.679\n","Epoch 68/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.52it/s, loss=0.319]\n","- Train loss : 0.319\n","- Eval metrics : acc: 83.960 ; loss: 0.477\n","- So far best epoch: 55, best acc: 86.679\n","Epoch 69/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.54it/s, loss=0.318]\n","- Train loss : 0.318\n","- Eval metrics : acc: 84.316 ; loss: 0.484\n","- So far best epoch: 55, best acc: 86.679\n","Epoch 70/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.55it/s, loss=0.318]\n","- Train loss : 0.318\n","- Eval metrics : acc: 84.701 ; loss: 0.471\n","- So far best epoch: 55, best acc: 86.679\n","Epoch 71/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.52it/s, loss=0.321]\n","- Train loss : 0.321\n","- Eval metrics : acc: 79.826 ; loss: 0.611\n","- So far best epoch: 55, best acc: 86.679\n","Epoch 72/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.53it/s, loss=0.314]\n","- Train loss : 0.314\n","- Eval metrics : acc: 82.417 ; loss: 0.521\n","- So far best epoch: 55, best acc: 86.679\n","Epoch 73/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.50it/s, loss=0.314]\n","- Train loss : 0.314\n","- Eval metrics : acc: 85.057 ; loss: 0.446\n","- So far best epoch: 55, best acc: 86.679\n","Epoch 74/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.54it/s, loss=0.318]\n","- Train loss : 0.318\n","- Eval metrics : acc: 80.845 ; loss: 0.565\n","- So far best epoch: 55, best acc: 86.679\n","Epoch 75/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.55it/s, loss=0.318]\n","- Train loss : 0.318\n","- Eval metrics : acc: 81.003 ; loss: 0.612\n","- So far best epoch: 55, best acc: 86.679\n","Epoch 76/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.46it/s, loss=0.319]\n","- Train loss : 0.319\n","- Eval metrics : acc: 85.680 ; loss: 0.425\n","- So far best epoch: 55, best acc: 86.679\n","Epoch 77/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.51it/s, loss=0.318]\n","- Train loss : 0.318\n","- Eval metrics : acc: 83.722 ; loss: 0.504\n","- So far best epoch: 55, best acc: 86.679\n","Epoch 78/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.52it/s, loss=0.318]\n","- Train loss : 0.318\n","- Eval metrics : acc: 83.623 ; loss: 0.493\n","- So far best epoch: 55, best acc: 86.679\n","Epoch 79/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.53it/s, loss=0.312]\n","- Train loss : 0.312\n","- Eval metrics : acc: 87.490 ; loss: 0.368\n","- New best model \n","- So far best epoch: 79, best acc: 87.490\n","Epoch 80/160\n","Learning Rate 0.1\n","100% 391/391 [00:18<00:00, 21.54it/s, loss=0.314]\n","- Train loss : 0.314\n","- Eval metrics : acc: 83.198 ; loss: 0.505\n","- So far best epoch: 79, best acc: 87.490\n","Epoch 81/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:18<00:00, 21.52it/s, loss=0.165]\n","- Train loss : 0.165\n","- Eval metrics : acc: 92.870 ; loss: 0.216\n","- New best model \n","- So far best epoch: 81, best acc: 92.870\n","Epoch 82/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:18<00:00, 21.53it/s, loss=0.116]\n","- Train loss : 0.116\n","- Eval metrics : acc: 93.078 ; loss: 0.206\n","- New best model \n","- So far best epoch: 82, best acc: 93.078\n","Epoch 83/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:18<00:00, 21.54it/s, loss=0.101]\n","- Train loss : 0.101\n","- Eval metrics : acc: 93.265 ; loss: 0.201\n","- New best model \n","- So far best epoch: 83, best acc: 93.265\n","Epoch 84/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:18<00:00, 21.51it/s, loss=0.086]\n","- Train loss : 0.086\n","- Eval metrics : acc: 93.572 ; loss: 0.193\n","- New best model \n","- So far best epoch: 84, best acc: 93.572\n","Epoch 85/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:18<00:00, 21.56it/s, loss=0.078]\n","- Train loss : 0.078\n","- Eval metrics : acc: 93.434 ; loss: 0.202\n","- So far best epoch: 84, best acc: 93.572\n","Epoch 86/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:18<00:00, 21.50it/s, loss=0.069]\n","- Train loss : 0.069\n","- Eval metrics : acc: 93.730 ; loss: 0.197\n","- New best model \n","- So far best epoch: 86, best acc: 93.730\n","Epoch 87/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:18<00:00, 21.45it/s, loss=0.059]\n","- Train loss : 0.059\n","- Eval metrics : acc: 93.859 ; loss: 0.198\n","- New best model \n","- So far best epoch: 87, best acc: 93.859\n","Epoch 88/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:18<00:00, 21.50it/s, loss=0.054]\n","- Train loss : 0.054\n","- Eval metrics : acc: 93.948 ; loss: 0.203\n","- New best model \n","- So far best epoch: 88, best acc: 93.948\n","Epoch 89/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:18<00:00, 21.48it/s, loss=0.050]\n","- Train loss : 0.050\n","- Eval metrics : acc: 93.918 ; loss: 0.205\n","- So far best epoch: 88, best acc: 93.948\n","Epoch 90/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:18<00:00, 21.50it/s, loss=0.045]\n","- Train loss : 0.045\n","- Eval metrics : acc: 93.671 ; loss: 0.209\n","- So far best epoch: 88, best acc: 93.948\n","Epoch 91/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:18<00:00, 21.51it/s, loss=0.042]\n","- Train loss : 0.042\n","- Eval metrics : acc: 93.770 ; loss: 0.215\n","- So far best epoch: 88, best acc: 93.948\n","Epoch 92/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:18<00:00, 21.51it/s, loss=0.041]\n","- Train loss : 0.041\n","- Eval metrics : acc: 93.809 ; loss: 0.215\n","- So far best epoch: 88, best acc: 93.948\n","Epoch 93/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:18<00:00, 21.52it/s, loss=0.038]\n","- Train loss : 0.038\n","- Eval metrics : acc: 94.047 ; loss: 0.209\n","- New best model \n","- So far best epoch: 93, best acc: 94.047\n","Epoch 94/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:18<00:00, 21.51it/s, loss=0.036]\n","- Train loss : 0.036\n","- Eval metrics : acc: 94.096 ; loss: 0.208\n","- New best model \n","- So far best epoch: 94, best acc: 94.096\n","Epoch 95/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:18<00:00, 21.47it/s, loss=0.033]\n","- Train loss : 0.033\n","- Eval metrics : acc: 93.612 ; loss: 0.225\n","- So far best epoch: 94, best acc: 94.096\n","Epoch 96/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:18<00:00, 21.48it/s, loss=0.033]\n","- Train loss : 0.033\n","- Eval metrics : acc: 93.879 ; loss: 0.215\n","- So far best epoch: 94, best acc: 94.096\n","Epoch 97/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:18<00:00, 21.45it/s, loss=0.033]\n","- Train loss : 0.033\n","- Eval metrics : acc: 93.621 ; loss: 0.222\n","- So far best epoch: 94, best acc: 94.096\n","Epoch 98/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:18<00:00, 21.55it/s, loss=0.034]\n","- Train loss : 0.034\n","- Eval metrics : acc: 93.364 ; loss: 0.229\n","- So far best epoch: 94, best acc: 94.096\n","Epoch 99/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:18<00:00, 21.53it/s, loss=0.031]\n","- Train loss : 0.031\n","- Eval metrics : acc: 93.325 ; loss: 0.231\n","- So far best epoch: 94, best acc: 94.096\n","Epoch 100/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:18<00:00, 21.55it/s, loss=0.031]\n","- Train loss : 0.031\n","- Eval metrics : acc: 93.582 ; loss: 0.233\n","- So far best epoch: 94, best acc: 94.096\n","Epoch 101/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:18<00:00, 21.52it/s, loss=0.029]\n","- Train loss : 0.029\n","- Eval metrics : acc: 93.799 ; loss: 0.223\n","- So far best epoch: 94, best acc: 94.096\n","Epoch 102/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:18<00:00, 21.54it/s, loss=0.030]\n","- Train loss : 0.030\n","- Eval metrics : acc: 93.335 ; loss: 0.239\n","- So far best epoch: 94, best acc: 94.096\n","Epoch 103/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:18<00:00, 21.52it/s, loss=0.028]\n","- Train loss : 0.028\n","- Eval metrics : acc: 92.405 ; loss: 0.279\n","- So far best epoch: 94, best acc: 94.096\n","Epoch 104/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:18<00:00, 21.54it/s, loss=0.033]\n","- Train loss : 0.033\n","- Eval metrics : acc: 93.424 ; loss: 0.241\n","- So far best epoch: 94, best acc: 94.096\n","Epoch 105/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:18<00:00, 21.53it/s, loss=0.030]\n","- Train loss : 0.030\n","- Eval metrics : acc: 93.008 ; loss: 0.252\n","- So far best epoch: 94, best acc: 94.096\n","Epoch 106/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:18<00:00, 21.47it/s, loss=0.034]\n","- Train loss : 0.034\n","- Eval metrics : acc: 93.404 ; loss: 0.240\n","- So far best epoch: 94, best acc: 94.096\n","Epoch 107/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:18<00:00, 21.50it/s, loss=0.034]\n","- Train loss : 0.034\n","- Eval metrics : acc: 93.256 ; loss: 0.243\n","- So far best epoch: 94, best acc: 94.096\n","Epoch 108/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:18<00:00, 21.54it/s, loss=0.036]\n","- Train loss : 0.036\n","- Eval metrics : acc: 92.722 ; loss: 0.266\n","- So far best epoch: 94, best acc: 94.096\n","Epoch 109/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:18<00:00, 21.53it/s, loss=0.036]\n","- Train loss : 0.036\n","- Eval metrics : acc: 93.068 ; loss: 0.241\n","- So far best epoch: 94, best acc: 94.096\n","Epoch 110/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:18<00:00, 21.57it/s, loss=0.040]\n","- Train loss : 0.040\n","- Eval metrics : acc: 92.702 ; loss: 0.256\n","- So far best epoch: 94, best acc: 94.096\n","Epoch 111/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:18<00:00, 21.51it/s, loss=0.036]\n","- Train loss : 0.036\n","- Eval metrics : acc: 93.503 ; loss: 0.238\n","- So far best epoch: 94, best acc: 94.096\n","Epoch 112/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:18<00:00, 21.51it/s, loss=0.034]\n","- Train loss : 0.034\n","- Eval metrics : acc: 93.256 ; loss: 0.254\n","- So far best epoch: 94, best acc: 94.096\n","Epoch 113/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:18<00:00, 21.49it/s, loss=0.043]\n","- Train loss : 0.043\n","- Eval metrics : acc: 93.078 ; loss: 0.247\n","- So far best epoch: 94, best acc: 94.096\n","Epoch 114/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:18<00:00, 21.51it/s, loss=0.041]\n","- Train loss : 0.041\n","- Eval metrics : acc: 92.375 ; loss: 0.271\n","- So far best epoch: 94, best acc: 94.096\n","Epoch 115/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:18<00:00, 21.51it/s, loss=0.040]\n","- Train loss : 0.040\n","- Eval metrics : acc: 92.811 ; loss: 0.261\n","- So far best epoch: 94, best acc: 94.096\n","Epoch 116/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:18<00:00, 21.48it/s, loss=0.042]\n","- Train loss : 0.042\n","- Eval metrics : acc: 92.247 ; loss: 0.281\n","- So far best epoch: 94, best acc: 94.096\n","Epoch 117/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:18<00:00, 21.50it/s, loss=0.041]\n","- Train loss : 0.041\n","- Eval metrics : acc: 92.741 ; loss: 0.270\n","- So far best epoch: 94, best acc: 94.096\n","Epoch 118/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:18<00:00, 21.51it/s, loss=0.044]\n","- Train loss : 0.044\n","- Eval metrics : acc: 92.702 ; loss: 0.264\n","- So far best epoch: 94, best acc: 94.096\n","Epoch 119/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:18<00:00, 21.51it/s, loss=0.044]\n","- Train loss : 0.044\n","- Eval metrics : acc: 92.445 ; loss: 0.270\n","- So far best epoch: 94, best acc: 94.096\n","Epoch 120/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:18<00:00, 21.51it/s, loss=0.047]\n","- Train loss : 0.047\n","- Eval metrics : acc: 93.196 ; loss: 0.250\n","- So far best epoch: 94, best acc: 94.096\n","Epoch 121/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:18<00:00, 21.52it/s, loss=0.022]\n","- Train loss : 0.022\n","- Eval metrics : acc: 94.264 ; loss: 0.202\n","- New best model \n","- So far best epoch: 121, best acc: 94.264\n","Epoch 122/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:18<00:00, 21.56it/s, loss=0.013]\n","- Train loss : 0.013\n","- Eval metrics : acc: 94.393 ; loss: 0.205\n","- New best model \n","- So far best epoch: 122, best acc: 94.393\n","Epoch 123/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:18<00:00, 21.55it/s, loss=0.011]\n","- Train loss : 0.011\n","- Eval metrics : acc: 94.403 ; loss: 0.204\n","- New best model \n","- So far best epoch: 123, best acc: 94.403\n","Epoch 124/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:18<00:00, 21.55it/s, loss=0.009]\n","- Train loss : 0.009\n","- Eval metrics : acc: 94.314 ; loss: 0.203\n","- So far best epoch: 123, best acc: 94.403\n","Epoch 125/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:18<00:00, 21.55it/s, loss=0.008]\n","- Train loss : 0.008\n","- Eval metrics : acc: 94.482 ; loss: 0.203\n","- New best model \n","- So far best epoch: 125, best acc: 94.482\n","Epoch 126/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:18<00:00, 21.49it/s, loss=0.007]\n","- Train loss : 0.007\n","- Eval metrics : acc: 94.353 ; loss: 0.205\n","- So far best epoch: 125, best acc: 94.482\n","Epoch 127/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:18<00:00, 21.55it/s, loss=0.007]\n","- Train loss : 0.007\n","- Eval metrics : acc: 94.492 ; loss: 0.204\n","- New best model \n","- So far best epoch: 127, best acc: 94.492\n","Epoch 128/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:18<00:00, 21.55it/s, loss=0.006]\n","- Train loss : 0.006\n","- Eval metrics : acc: 94.531 ; loss: 0.202\n","- New best model \n","- So far best epoch: 128, best acc: 94.531\n","Epoch 129/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:18<00:00, 21.57it/s, loss=0.006]\n","- Train loss : 0.006\n","- Eval metrics : acc: 94.620 ; loss: 0.202\n","- New best model \n","- So far best epoch: 129, best acc: 94.620\n","Epoch 130/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:18<00:00, 21.56it/s, loss=0.006]\n","- Train loss : 0.006\n","- Eval metrics : acc: 94.521 ; loss: 0.203\n","- So far best epoch: 129, best acc: 94.620\n","Epoch 131/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:18<00:00, 21.53it/s, loss=0.005]\n","- Train loss : 0.005\n","- Eval metrics : acc: 94.630 ; loss: 0.203\n","- New best model \n","- So far best epoch: 131, best acc: 94.630\n","Epoch 132/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:18<00:00, 21.52it/s, loss=0.005]\n","- Train loss : 0.005\n","- Eval metrics : acc: 94.650 ; loss: 0.203\n","- New best model \n","- So far best epoch: 132, best acc: 94.650\n","Epoch 133/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:18<00:00, 21.55it/s, loss=0.005]\n","- Train loss : 0.005\n","- Eval metrics : acc: 94.571 ; loss: 0.204\n","- So far best epoch: 132, best acc: 94.650\n","Epoch 134/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:18<00:00, 21.50it/s, loss=0.005]\n","- Train loss : 0.005\n","- Eval metrics : acc: 94.620 ; loss: 0.204\n","- So far best epoch: 132, best acc: 94.650\n","Epoch 135/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:18<00:00, 21.54it/s, loss=0.004]\n","- Train loss : 0.004\n","- Eval metrics : acc: 94.620 ; loss: 0.204\n","- So far best epoch: 132, best acc: 94.650\n","Epoch 136/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:18<00:00, 21.49it/s, loss=0.004]\n","- Train loss : 0.004\n","- Eval metrics : acc: 94.709 ; loss: 0.205\n","- New best model \n","- So far best epoch: 136, best acc: 94.709\n","Epoch 137/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:18<00:00, 21.53it/s, loss=0.004]\n","- Train loss : 0.004\n","- Eval metrics : acc: 94.670 ; loss: 0.204\n","- So far best epoch: 136, best acc: 94.709\n","Epoch 138/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:18<00:00, 21.58it/s, loss=0.004]\n","- Train loss : 0.004\n","- Eval metrics : acc: 94.689 ; loss: 0.204\n","- So far best epoch: 136, best acc: 94.709\n","Epoch 139/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:18<00:00, 21.54it/s, loss=0.004]\n","- Train loss : 0.004\n","- Eval metrics : acc: 94.610 ; loss: 0.205\n","- So far best epoch: 136, best acc: 94.709\n","Epoch 140/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:18<00:00, 21.50it/s, loss=0.004]\n","- Train loss : 0.004\n","- Eval metrics : acc: 94.600 ; loss: 0.206\n","- So far best epoch: 136, best acc: 94.709\n","Epoch 141/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:18<00:00, 21.47it/s, loss=0.004]\n","- Train loss : 0.004\n","- Eval metrics : acc: 94.551 ; loss: 0.205\n","- So far best epoch: 136, best acc: 94.709\n","Epoch 142/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:18<00:00, 21.49it/s, loss=0.004]\n","- Train loss : 0.004\n","- Eval metrics : acc: 94.620 ; loss: 0.206\n","- So far best epoch: 136, best acc: 94.709\n","Epoch 143/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:18<00:00, 21.49it/s, loss=0.004]\n","- Train loss : 0.004\n","- Eval metrics : acc: 94.650 ; loss: 0.205\n","- So far best epoch: 136, best acc: 94.709\n","Epoch 144/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:18<00:00, 21.53it/s, loss=0.003]\n","- Train loss : 0.003\n","- Eval metrics : acc: 94.729 ; loss: 0.204\n","- New best model \n","- So far best epoch: 144, best acc: 94.729\n","Epoch 145/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:18<00:00, 21.56it/s, loss=0.003]\n","- Train loss : 0.003\n","- Eval metrics : acc: 94.561 ; loss: 0.206\n","- So far best epoch: 144, best acc: 94.729\n","Epoch 146/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:18<00:00, 21.47it/s, loss=0.003]\n","- Train loss : 0.003\n","- Eval metrics : acc: 94.660 ; loss: 0.204\n","- So far best epoch: 144, best acc: 94.729\n","Epoch 147/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:18<00:00, 21.52it/s, loss=0.003]\n","- Train loss : 0.003\n","- Eval metrics : acc: 94.660 ; loss: 0.203\n","- So far best epoch: 144, best acc: 94.729\n","Epoch 148/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:18<00:00, 21.54it/s, loss=0.003]\n","- Train loss : 0.003\n","- Eval metrics : acc: 94.680 ; loss: 0.203\n","- So far best epoch: 144, best acc: 94.729\n","Epoch 149/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:18<00:00, 21.53it/s, loss=0.003]\n","- Train loss : 0.003\n","- Eval metrics : acc: 94.680 ; loss: 0.203\n","- So far best epoch: 144, best acc: 94.729\n","Epoch 150/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:18<00:00, 21.49it/s, loss=0.003]\n","- Train loss : 0.003\n","- Eval metrics : acc: 94.759 ; loss: 0.204\n","- New best model \n","- So far best epoch: 150, best acc: 94.759\n","Epoch 151/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:18<00:00, 21.53it/s, loss=0.003]\n","- Train loss : 0.003\n","- Eval metrics : acc: 94.680 ; loss: 0.203\n","- So far best epoch: 150, best acc: 94.759\n","Epoch 152/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:18<00:00, 21.51it/s, loss=0.003]\n","- Train loss : 0.003\n","- Eval metrics : acc: 94.729 ; loss: 0.204\n","- So far best epoch: 150, best acc: 94.759\n","Epoch 153/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:18<00:00, 21.54it/s, loss=0.003]\n","- Train loss : 0.003\n","- Eval metrics : acc: 94.739 ; loss: 0.203\n","- So far best epoch: 150, best acc: 94.759\n","Epoch 154/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:18<00:00, 21.54it/s, loss=0.003]\n","- Train loss : 0.003\n","- Eval metrics : acc: 94.749 ; loss: 0.204\n","- So far best epoch: 150, best acc: 94.759\n","Epoch 155/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:18<00:00, 21.54it/s, loss=0.003]\n","- Train loss : 0.003\n","- Eval metrics : acc: 94.798 ; loss: 0.202\n","- New best model \n","- So far best epoch: 155, best acc: 94.798\n","Epoch 156/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:18<00:00, 21.51it/s, loss=0.003]\n","- Train loss : 0.003\n","- Eval metrics : acc: 94.808 ; loss: 0.202\n","- New best model \n","- So far best epoch: 156, best acc: 94.808\n","Epoch 157/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:18<00:00, 21.49it/s, loss=0.003]\n","- Train loss : 0.003\n","- Eval metrics : acc: 94.680 ; loss: 0.202\n","- So far best epoch: 156, best acc: 94.808\n","Epoch 158/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:18<00:00, 21.46it/s, loss=0.003]\n","- Train loss : 0.003\n","- Eval metrics : acc: 94.699 ; loss: 0.201\n","- So far best epoch: 156, best acc: 94.808\n","Epoch 159/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:18<00:00, 21.46it/s, loss=0.002]\n","- Train loss : 0.002\n","- Eval metrics : acc: 94.749 ; loss: 0.199\n","- So far best epoch: 156, best acc: 94.808\n","Epoch 160/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:18<00:00, 21.53it/s, loss=0.003]\n","- Train loss : 0.003\n","- Eval metrics : acc: 94.818 ; loss: 0.201\n","- New best model \n","- So far best epoch: 160, best acc: 94.818\n"]}],"source":["!python train_scratch.py --save_path experiments/CIFAR10/baseline/resnet18"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1524087,"status":"ok","timestamp":1717941931337,"user":{"displayName":"bilge gunsel","userId":"10924216968931407832"},"user_tz":-180},"id":"g0NWxVTSyrba","outputId":"c8528543-a264-4e54-c00f-cf9bd8d5552f"},"outputs":[{"name":"stdout","output_type":"stream","text":["model_name:resnet18\n","learning_rate:0.1\n","schedule:[80, 120]\n","gamma:0.1\n","batch_size:128\n","num_epochs:160\n","num_workers:4\n","augmentation:1\n","cuda:True\n","dataset:cifar10\n","adversarial_model:resnet18\n","adversarial_resume:experiments/CIFAR10/baseline/resnet18/best_model.tar\n","temperature:4\n","weight:0.04\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Number of class: 10\n","Create Model --- resnet18\n","Create Adversarial Model --- resnet18\n","- Train from scratch \n","- Load Trained adversarial model from experiments/CIFAR10/baseline/resnet18/best_model.tar\n","Optimizer: SGD\n","Epoch 1/160\n","Learning Rate 0.1\n","100% 391/391 [00:25<00:00, 15.33it/s, loss=101.528]\n","- Train loss : 101.528\n","- Train teacher loss : 1.852\n","- Train adversarial loss : 8.091\n","- Eval metrics : acc: 43.651 ; loss: 1.540\n","- New best model \n","- So far best epoch: 1, best acc: 43.651\n","Epoch 2/160\n","Learning Rate 0.1\n","100% 391/391 [00:23<00:00, 17.00it/s, loss=101.121]\n","- Train loss : 101.121\n","- Train teacher loss : 1.417\n","- Train adversarial loss : 7.396\n","- Eval metrics : acc: 53.550 ; loss: 1.269\n","- New best model \n","- So far best epoch: 2, best acc: 53.550\n","Epoch 3/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.24it/s, loss=100.883]\n","- Train loss : 100.883\n","- Train teacher loss : 1.173\n","- Train adversarial loss : 7.233\n","- Eval metrics : acc: 57.911 ; loss: 1.224\n","- New best model \n","- So far best epoch: 3, best acc: 57.911\n","Epoch 4/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.30it/s, loss=100.691]\n","- Train loss : 100.691\n","- Train teacher loss : 0.982\n","- Train adversarial loss : 7.284\n","- Eval metrics : acc: 69.195 ; loss: 0.876\n","- New best model \n","- So far best epoch: 4, best acc: 69.195\n","Epoch 5/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.22it/s, loss=100.531]\n","- Train loss : 100.531\n","- Train teacher loss : 0.818\n","- Train adversarial loss : 7.160\n","- Eval metrics : acc: 69.492 ; loss: 0.927\n","- New best model \n","- So far best epoch: 5, best acc: 69.492\n","Epoch 6/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.18it/s, loss=100.432]\n","- Train loss : 100.432\n","- Train teacher loss : 0.715\n","- Train adversarial loss : 7.069\n","- Eval metrics : acc: 72.280 ; loss: 0.851\n","- New best model \n","- So far best epoch: 6, best acc: 72.280\n","Epoch 7/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.23it/s, loss=100.370]\n","- Train loss : 100.370\n","- Train teacher loss : 0.652\n","- Train adversarial loss : 7.055\n","- Eval metrics : acc: 71.262 ; loss: 0.830\n","- So far best epoch: 6, best acc: 72.280\n","Epoch 8/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.27it/s, loss=100.333]\n","- Train loss : 100.333\n","- Train teacher loss : 0.616\n","- Train adversarial loss : 7.075\n","- Eval metrics : acc: 76.038 ; loss: 0.696\n","- New best model \n","- So far best epoch: 8, best acc: 76.038\n","Epoch 9/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.26it/s, loss=100.303]\n","- Train loss : 100.303\n","- Train teacher loss : 0.588\n","- Train adversarial loss : 7.117\n","- Eval metrics : acc: 76.978 ; loss: 0.681\n","- New best model \n","- So far best epoch: 9, best acc: 76.978\n","Epoch 10/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.24it/s, loss=100.284]\n","- Train loss : 100.284\n","- Train teacher loss : 0.572\n","- Train adversarial loss : 7.218\n","- Eval metrics : acc: 78.659 ; loss: 0.687\n","- New best model \n","- So far best epoch: 10, best acc: 78.659\n","Epoch 11/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.24it/s, loss=100.261]\n","- Train loss : 100.261\n","- Train teacher loss : 0.555\n","- Train adversarial loss : 7.363\n","- Eval metrics : acc: 78.273 ; loss: 0.652\n","- So far best epoch: 10, best acc: 78.659\n","Epoch 12/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.23it/s, loss=100.252]\n","- Train loss : 100.252\n","- Train teacher loss : 0.548\n","- Train adversarial loss : 7.410\n","- Eval metrics : acc: 72.884 ; loss: 0.903\n","- So far best epoch: 10, best acc: 78.659\n","Epoch 13/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.25it/s, loss=100.236]\n","- Train loss : 100.236\n","- Train teacher loss : 0.533\n","- Train adversarial loss : 7.427\n","- Eval metrics : acc: 79.450 ; loss: 0.616\n","- New best model \n","- So far best epoch: 13, best acc: 79.450\n","Epoch 14/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.24it/s, loss=100.223]\n","- Train loss : 100.223\n","- Train teacher loss : 0.524\n","- Train adversarial loss : 7.530\n","- Eval metrics : acc: 78.224 ; loss: 0.787\n","- So far best epoch: 13, best acc: 79.450\n","Epoch 15/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.25it/s, loss=100.213]\n","- Train loss : 100.213\n","- Train teacher loss : 0.514\n","- Train adversarial loss : 7.532\n","- Eval metrics : acc: 77.403 ; loss: 0.707\n","- So far best epoch: 13, best acc: 79.450\n","Epoch 16/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.25it/s, loss=100.201]\n","- Train loss : 100.201\n","- Train teacher loss : 0.507\n","- Train adversarial loss : 7.648\n","- Eval metrics : acc: 73.705 ; loss: 0.861\n","- So far best epoch: 13, best acc: 79.450\n","Epoch 17/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.25it/s, loss=100.203]\n","- Train loss : 100.203\n","- Train teacher loss : 0.506\n","- Train adversarial loss : 7.592\n","- Eval metrics : acc: 78.837 ; loss: 0.637\n","- So far best epoch: 13, best acc: 79.450\n","Epoch 18/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.25it/s, loss=100.182]\n","- Train loss : 100.182\n","- Train teacher loss : 0.490\n","- Train adversarial loss : 7.705\n","- Eval metrics : acc: 80.983 ; loss: 0.663\n","- New best model \n","- So far best epoch: 18, best acc: 80.983\n","Epoch 19/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.27it/s, loss=100.190]\n","- Train loss : 100.190\n","- Train teacher loss : 0.496\n","- Train adversarial loss : 7.659\n","- Eval metrics : acc: 79.252 ; loss: 0.646\n","- So far best epoch: 18, best acc: 80.983\n","Epoch 20/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.25it/s, loss=100.178]\n","- Train loss : 100.178\n","- Train teacher loss : 0.486\n","- Train adversarial loss : 7.701\n","- Eval metrics : acc: 81.576 ; loss: 0.606\n","- New best model \n","- So far best epoch: 20, best acc: 81.576\n","Epoch 21/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.29it/s, loss=100.170]\n","- Train loss : 100.170\n","- Train teacher loss : 0.481\n","- Train adversarial loss : 7.776\n","- Eval metrics : acc: 79.836 ; loss: 0.689\n","- So far best epoch: 20, best acc: 81.576\n","Epoch 22/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.27it/s, loss=100.176]\n","- Train loss : 100.176\n","- Train teacher loss : 0.488\n","- Train adversarial loss : 7.801\n","- Eval metrics : acc: 83.287 ; loss: 0.551\n","- New best model \n","- So far best epoch: 22, best acc: 83.287\n","Epoch 23/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.27it/s, loss=100.166]\n","- Train loss : 100.166\n","- Train teacher loss : 0.480\n","- Train adversarial loss : 7.845\n","- Eval metrics : acc: 81.359 ; loss: 0.596\n","- So far best epoch: 22, best acc: 83.287\n","Epoch 24/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.25it/s, loss=100.158]\n","- Train loss : 100.158\n","- Train teacher loss : 0.474\n","- Train adversarial loss : 7.902\n","- Eval metrics : acc: 74.743 ; loss: 0.886\n","- So far best epoch: 22, best acc: 83.287\n","Epoch 25/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.28it/s, loss=100.162]\n","- Train loss : 100.162\n","- Train teacher loss : 0.476\n","- Train adversarial loss : 7.858\n","- Eval metrics : acc: 77.314 ; loss: 0.765\n","- So far best epoch: 22, best acc: 83.287\n","Epoch 26/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.26it/s, loss=100.154]\n","- Train loss : 100.154\n","- Train teacher loss : 0.472\n","- Train adversarial loss : 7.950\n","- Eval metrics : acc: 80.914 ; loss: 0.608\n","- So far best epoch: 22, best acc: 83.287\n","Epoch 27/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.28it/s, loss=100.161]\n","- Train loss : 100.161\n","- Train teacher loss : 0.476\n","- Train adversarial loss : 7.886\n","- Eval metrics : acc: 83.643 ; loss: 0.554\n","- New best model \n","- So far best epoch: 27, best acc: 83.643\n","Epoch 28/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.27it/s, loss=100.145]\n","- Train loss : 100.145\n","- Train teacher loss : 0.464\n","- Train adversarial loss : 7.975\n","- Eval metrics : acc: 81.804 ; loss: 0.647\n","- So far best epoch: 27, best acc: 83.643\n","Epoch 29/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.25it/s, loss=100.147]\n","- Train loss : 100.147\n","- Train teacher loss : 0.467\n","- Train adversarial loss : 8.003\n","- Eval metrics : acc: 80.400 ; loss: 0.617\n","- So far best epoch: 27, best acc: 83.643\n","Epoch 30/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.24it/s, loss=100.141]\n","- Train loss : 100.141\n","- Train teacher loss : 0.462\n","- Train adversarial loss : 8.012\n","- Eval metrics : acc: 79.015 ; loss: 0.713\n","- So far best epoch: 27, best acc: 83.643\n","Epoch 31/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.29it/s, loss=100.145]\n","- Train loss : 100.145\n","- Train teacher loss : 0.469\n","- Train adversarial loss : 8.101\n","- Eval metrics : acc: 76.919 ; loss: 0.778\n","- So far best epoch: 27, best acc: 83.643\n","Epoch 32/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.27it/s, loss=100.141]\n","- Train loss : 100.141\n","- Train teacher loss : 0.462\n","- Train adversarial loss : 8.013\n","- Eval metrics : acc: 81.032 ; loss: 0.677\n","- So far best epoch: 27, best acc: 83.643\n","Epoch 33/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.33it/s, loss=100.136]\n","- Train loss : 100.136\n","- Train teacher loss : 0.458\n","- Train adversarial loss : 8.057\n","- Eval metrics : acc: 83.327 ; loss: 0.554\n","- So far best epoch: 27, best acc: 83.643\n","Epoch 34/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.29it/s, loss=100.141]\n","- Train loss : 100.141\n","- Train teacher loss : 0.464\n","- Train adversarial loss : 8.085\n","- Eval metrics : acc: 81.319 ; loss: 0.582\n","- So far best epoch: 27, best acc: 83.643\n","Epoch 35/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.28it/s, loss=100.134]\n","- Train loss : 100.134\n","- Train teacher loss : 0.459\n","- Train adversarial loss : 8.110\n","- Eval metrics : acc: 81.290 ; loss: 0.752\n","- So far best epoch: 27, best acc: 83.643\n","Epoch 36/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.27it/s, loss=100.135]\n","- Train loss : 100.135\n","- Train teacher loss : 0.460\n","- Train adversarial loss : 8.123\n","- Eval metrics : acc: 79.242 ; loss: 0.718\n","- So far best epoch: 27, best acc: 83.643\n","Epoch 37/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.24it/s, loss=100.128]\n","- Train loss : 100.128\n","- Train teacher loss : 0.454\n","- Train adversarial loss : 8.155\n","- Eval metrics : acc: 83.267 ; loss: 0.580\n","- So far best epoch: 27, best acc: 83.643\n","Epoch 38/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.29it/s, loss=100.131]\n","- Train loss : 100.131\n","- Train teacher loss : 0.457\n","- Train adversarial loss : 8.156\n","- Eval metrics : acc: 83.673 ; loss: 0.586\n","- New best model \n","- So far best epoch: 38, best acc: 83.673\n","Epoch 39/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.29it/s, loss=100.131]\n","- Train loss : 100.131\n","- Train teacher loss : 0.461\n","- Train adversarial loss : 8.231\n","- Eval metrics : acc: 76.592 ; loss: 0.865\n","- So far best epoch: 38, best acc: 83.673\n","Epoch 40/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.29it/s, loss=100.123]\n","- Train loss : 100.123\n","- Train teacher loss : 0.452\n","- Train adversarial loss : 8.222\n","- Eval metrics : acc: 72.429 ; loss: 1.021\n","- So far best epoch: 38, best acc: 83.673\n","Epoch 41/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.31it/s, loss=100.123]\n","- Train loss : 100.123\n","- Train teacher loss : 0.450\n","- Train adversarial loss : 8.180\n","- Eval metrics : acc: 79.490 ; loss: 0.666\n","- So far best epoch: 38, best acc: 83.673\n","Epoch 42/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.28it/s, loss=100.121]\n","- Train loss : 100.121\n","- Train teacher loss : 0.452\n","- Train adversarial loss : 8.284\n","- Eval metrics : acc: 82.011 ; loss: 0.602\n","- So far best epoch: 38, best acc: 83.673\n","Epoch 43/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.25it/s, loss=100.125]\n","- Train loss : 100.125\n","- Train teacher loss : 0.455\n","- Train adversarial loss : 8.254\n","- Eval metrics : acc: 80.024 ; loss: 0.805\n","- So far best epoch: 38, best acc: 83.673\n","Epoch 44/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.26it/s, loss=100.119]\n","- Train loss : 100.119\n","- Train teacher loss : 0.449\n","- Train adversarial loss : 8.262\n","- Eval metrics : acc: 77.700 ; loss: 0.724\n","- So far best epoch: 38, best acc: 83.673\n","Epoch 45/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.30it/s, loss=100.125]\n","- Train loss : 100.125\n","- Train teacher loss : 0.455\n","- Train adversarial loss : 8.256\n","- Eval metrics : acc: 79.252 ; loss: 0.677\n","- So far best epoch: 38, best acc: 83.673\n","Epoch 46/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.29it/s, loss=100.111]\n","- Train loss : 100.111\n","- Train teacher loss : 0.443\n","- Train adversarial loss : 8.311\n","- Eval metrics : acc: 79.371 ; loss: 0.707\n","- So far best epoch: 38, best acc: 83.673\n","Epoch 47/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.26it/s, loss=100.126]\n","- Train loss : 100.126\n","- Train teacher loss : 0.459\n","- Train adversarial loss : 8.324\n","- Eval metrics : acc: 78.985 ; loss: 0.633\n","- So far best epoch: 38, best acc: 83.673\n","Epoch 48/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.30it/s, loss=100.109]\n","- Train loss : 100.109\n","- Train teacher loss : 0.441\n","- Train adversarial loss : 8.293\n","- Eval metrics : acc: 78.778 ; loss: 0.752\n","- So far best epoch: 38, best acc: 83.673\n","Epoch 49/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.29it/s, loss=100.120]\n","- Train loss : 100.120\n","- Train teacher loss : 0.452\n","- Train adversarial loss : 8.288\n","- Eval metrics : acc: 82.397 ; loss: 0.629\n","- So far best epoch: 38, best acc: 83.673\n","Epoch 50/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.28it/s, loss=100.107]\n","- Train loss : 100.107\n","- Train teacher loss : 0.442\n","- Train adversarial loss : 8.362\n","- Eval metrics : acc: 84.167 ; loss: 0.501\n","- New best model \n","- So far best epoch: 50, best acc: 84.167\n","Epoch 51/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.30it/s, loss=100.113]\n","- Train loss : 100.113\n","- Train teacher loss : 0.446\n","- Train adversarial loss : 8.308\n","- Eval metrics : acc: 84.266 ; loss: 0.526\n","- New best model \n","- So far best epoch: 51, best acc: 84.266\n","Epoch 52/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.30it/s, loss=100.115]\n","- Train loss : 100.115\n","- Train teacher loss : 0.446\n","- Train adversarial loss : 8.271\n","- Eval metrics : acc: 82.902 ; loss: 0.536\n","- So far best epoch: 51, best acc: 84.266\n","Epoch 53/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.29it/s, loss=100.116]\n","- Train loss : 100.116\n","- Train teacher loss : 0.449\n","- Train adversarial loss : 8.315\n","- Eval metrics : acc: 82.011 ; loss: 0.616\n","- So far best epoch: 51, best acc: 84.266\n","Epoch 54/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.31it/s, loss=100.118]\n","- Train loss : 100.118\n","- Train teacher loss : 0.450\n","- Train adversarial loss : 8.308\n","- Eval metrics : acc: 79.361 ; loss: 0.795\n","- So far best epoch: 51, best acc: 84.266\n","Epoch 55/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.29it/s, loss=100.106]\n","- Train loss : 100.106\n","- Train teacher loss : 0.438\n","- Train adversarial loss : 8.307\n","- Eval metrics : acc: 82.269 ; loss: 0.590\n","- So far best epoch: 51, best acc: 84.266\n","Epoch 56/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.29it/s, loss=100.118]\n","- Train loss : 100.118\n","- Train teacher loss : 0.449\n","- Train adversarial loss : 8.281\n","- Eval metrics : acc: 84.682 ; loss: 0.500\n","- New best model \n","- So far best epoch: 56, best acc: 84.682\n","Epoch 57/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.29it/s, loss=100.105]\n","- Train loss : 100.105\n","- Train teacher loss : 0.439\n","- Train adversarial loss : 8.330\n","- Eval metrics : acc: 83.080 ; loss: 0.526\n","- So far best epoch: 56, best acc: 84.682\n","Epoch 58/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.31it/s, loss=100.116]\n","- Train loss : 100.116\n","- Train teacher loss : 0.449\n","- Train adversarial loss : 8.330\n","- Eval metrics : acc: 79.430 ; loss: 0.658\n","- So far best epoch: 56, best acc: 84.682\n","Epoch 59/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.30it/s, loss=100.097]\n","- Train loss : 100.097\n","- Train teacher loss : 0.432\n","- Train adversarial loss : 8.383\n","- Eval metrics : acc: 79.351 ; loss: 0.673\n","- So far best epoch: 56, best acc: 84.682\n","Epoch 60/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.31it/s, loss=100.111]\n","- Train loss : 100.111\n","- Train teacher loss : 0.444\n","- Train adversarial loss : 8.323\n","- Eval metrics : acc: 82.427 ; loss: 0.568\n","- So far best epoch: 56, best acc: 84.682\n","Epoch 61/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.33it/s, loss=100.109]\n","- Train loss : 100.109\n","- Train teacher loss : 0.443\n","- Train adversarial loss : 8.375\n","- Eval metrics : acc: 79.272 ; loss: 0.660\n","- So far best epoch: 56, best acc: 84.682\n","Epoch 62/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.36it/s, loss=100.100]\n","- Train loss : 100.100\n","- Train teacher loss : 0.433\n","- Train adversarial loss : 8.335\n","- Eval metrics : acc: 79.598 ; loss: 0.633\n","- So far best epoch: 56, best acc: 84.682\n","Epoch 63/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.31it/s, loss=100.110]\n","- Train loss : 100.110\n","- Train teacher loss : 0.444\n","- Train adversarial loss : 8.347\n","- Eval metrics : acc: 81.903 ; loss: 0.580\n","- So far best epoch: 56, best acc: 84.682\n","Epoch 64/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.32it/s, loss=100.104]\n","- Train loss : 100.104\n","- Train teacher loss : 0.436\n","- Train adversarial loss : 8.318\n","- Eval metrics : acc: 81.932 ; loss: 0.631\n","- So far best epoch: 56, best acc: 84.682\n","Epoch 65/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.33it/s, loss=100.109]\n","- Train loss : 100.109\n","- Train teacher loss : 0.443\n","- Train adversarial loss : 8.357\n","- Eval metrics : acc: 82.021 ; loss: 0.563\n","- So far best epoch: 56, best acc: 84.682\n","Epoch 66/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.32it/s, loss=100.105]\n","- Train loss : 100.105\n","- Train teacher loss : 0.439\n","- Train adversarial loss : 8.336\n","- Eval metrics : acc: 76.731 ; loss: 0.810\n","- So far best epoch: 56, best acc: 84.682\n","Epoch 67/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.31it/s, loss=100.113]\n","- Train loss : 100.113\n","- Train teacher loss : 0.447\n","- Train adversarial loss : 8.339\n","- Eval metrics : acc: 81.774 ; loss: 0.595\n","- So far best epoch: 56, best acc: 84.682\n","Epoch 68/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.31it/s, loss=100.107]\n","- Train loss : 100.107\n","- Train teacher loss : 0.440\n","- Train adversarial loss : 8.328\n","- Eval metrics : acc: 83.752 ; loss: 0.536\n","- So far best epoch: 56, best acc: 84.682\n","Epoch 69/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.33it/s, loss=100.103]\n","- Train loss : 100.103\n","- Train teacher loss : 0.437\n","- Train adversarial loss : 8.353\n","- Eval metrics : acc: 76.315 ; loss: 0.747\n","- So far best epoch: 56, best acc: 84.682\n","Epoch 70/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.32it/s, loss=100.111]\n","- Train loss : 100.111\n","- Train teacher loss : 0.445\n","- Train adversarial loss : 8.349\n","- Eval metrics : acc: 81.240 ; loss: 0.590\n","- So far best epoch: 56, best acc: 84.682\n","Epoch 71/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.32it/s, loss=100.107]\n","- Train loss : 100.107\n","- Train teacher loss : 0.440\n","- Train adversarial loss : 8.314\n","- Eval metrics : acc: 84.316 ; loss: 0.557\n","- So far best epoch: 56, best acc: 84.682\n","Epoch 72/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.30it/s, loss=100.101]\n","- Train loss : 100.101\n","- Train teacher loss : 0.436\n","- Train adversarial loss : 8.379\n","- Eval metrics : acc: 82.209 ; loss: 0.596\n","- So far best epoch: 56, best acc: 84.682\n","Epoch 73/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.31it/s, loss=100.100]\n","- Train loss : 100.100\n","- Train teacher loss : 0.435\n","- Train adversarial loss : 8.367\n","- Eval metrics : acc: 84.148 ; loss: 0.517\n","- So far best epoch: 56, best acc: 84.682\n","Epoch 74/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.33it/s, loss=100.107]\n","- Train loss : 100.107\n","- Train teacher loss : 0.443\n","- Train adversarial loss : 8.406\n","- Eval metrics : acc: 78.392 ; loss: 0.667\n","- So far best epoch: 56, best acc: 84.682\n","Epoch 75/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.31it/s, loss=100.103]\n","- Train loss : 100.103\n","- Train teacher loss : 0.439\n","- Train adversarial loss : 8.387\n","- Eval metrics : acc: 81.042 ; loss: 0.635\n","- So far best epoch: 56, best acc: 84.682\n","Epoch 76/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.31it/s, loss=100.096]\n","- Train loss : 100.096\n","- Train teacher loss : 0.430\n","- Train adversarial loss : 8.348\n","- Eval metrics : acc: 82.931 ; loss: 0.613\n","- So far best epoch: 56, best acc: 84.682\n","Epoch 77/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.33it/s, loss=100.109]\n","- Train loss : 100.109\n","- Train teacher loss : 0.444\n","- Train adversarial loss : 8.375\n","- Eval metrics : acc: 79.757 ; loss: 0.641\n","- So far best epoch: 56, best acc: 84.682\n","Epoch 78/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.33it/s, loss=100.104]\n","- Train loss : 100.104\n","- Train teacher loss : 0.435\n","- Train adversarial loss : 8.273\n","- Eval metrics : acc: 80.202 ; loss: 0.661\n","- So far best epoch: 56, best acc: 84.682\n","Epoch 79/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.31it/s, loss=100.098]\n","- Train loss : 100.098\n","- Train teacher loss : 0.433\n","- Train adversarial loss : 8.376\n","- Eval metrics : acc: 80.894 ; loss: 0.646\n","- So far best epoch: 56, best acc: 84.682\n","Epoch 80/160\n","Learning Rate 0.1\n","100% 391/391 [00:22<00:00, 17.31it/s, loss=100.108]\n","- Train loss : 100.108\n","- Train teacher loss : 0.441\n","- Train adversarial loss : 8.316\n","- Eval metrics : acc: 74.644 ; loss: 0.975\n","- So far best epoch: 56, best acc: 84.682\n","Epoch 81/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:22<00:00, 17.32it/s, loss=99.936]\n","- Train loss : 99.936\n","- Train teacher loss : 0.278\n","- Train adversarial loss : 8.539\n","- Eval metrics : acc: 91.693 ; loss: 0.294\n","- New best model \n","- So far best epoch: 81, best acc: 91.693\n","Epoch 82/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:22<00:00, 17.31it/s, loss=99.862]\n","- Train loss : 99.862\n","- Train teacher loss : 0.221\n","- Train adversarial loss : 8.961\n","- Eval metrics : acc: 92.079 ; loss: 0.297\n","- New best model \n","- So far best epoch: 82, best acc: 92.079\n","Epoch 83/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:22<00:00, 17.32it/s, loss=99.838]\n","- Train loss : 99.838\n","- Train teacher loss : 0.206\n","- Train adversarial loss : 9.199\n","- Eval metrics : acc: 92.227 ; loss: 0.294\n","- New best model \n","- So far best epoch: 83, best acc: 92.227\n","Epoch 84/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:22<00:00, 17.32it/s, loss=99.816]\n","- Train loss : 99.816\n","- Train teacher loss : 0.192\n","- Train adversarial loss : 9.381\n","- Eval metrics : acc: 92.830 ; loss: 0.310\n","- New best model \n","- So far best epoch: 84, best acc: 92.830\n","Epoch 85/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:22<00:00, 17.32it/s, loss=99.802]\n","- Train loss : 99.802\n","- Train teacher loss : 0.183\n","- Train adversarial loss : 9.534\n","- Eval metrics : acc: 92.781 ; loss: 0.300\n","- So far best epoch: 84, best acc: 92.830\n","Epoch 86/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:22<00:00, 17.31it/s, loss=99.792]\n","- Train loss : 99.792\n","- Train teacher loss : 0.175\n","- Train adversarial loss : 9.594\n","- Eval metrics : acc: 92.425 ; loss: 0.310\n","- So far best epoch: 84, best acc: 92.830\n","Epoch 87/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:22<00:00, 17.32it/s, loss=99.780]\n","- Train loss : 99.780\n","- Train teacher loss : 0.167\n","- Train adversarial loss : 9.683\n","- Eval metrics : acc: 92.504 ; loss: 0.322\n","- So far best epoch: 84, best acc: 92.830\n","Epoch 88/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:22<00:00, 17.36it/s, loss=99.772]\n","- Train loss : 99.772\n","- Train teacher loss : 0.162\n","- Train adversarial loss : 9.738\n","- Eval metrics : acc: 92.771 ; loss: 0.309\n","- So far best epoch: 84, best acc: 92.830\n","Epoch 89/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:22<00:00, 17.34it/s, loss=99.767]\n","- Train loss : 99.767\n","- Train teacher loss : 0.159\n","- Train adversarial loss : 9.788\n","- Eval metrics : acc: 92.722 ; loss: 0.341\n","- So far best epoch: 84, best acc: 92.830\n","Epoch 90/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:22<00:00, 17.33it/s, loss=99.768]\n","- Train loss : 99.768\n","- Train teacher loss : 0.160\n","- Train adversarial loss : 9.807\n","- Eval metrics : acc: 92.791 ; loss: 0.336\n","- So far best epoch: 84, best acc: 92.830\n","Epoch 91/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:22<00:00, 17.33it/s, loss=99.758]\n","- Train loss : 99.758\n","- Train teacher loss : 0.151\n","- Train adversarial loss : 9.842\n","- Eval metrics : acc: 92.613 ; loss: 0.359\n","- So far best epoch: 84, best acc: 92.830\n","Epoch 92/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:22<00:00, 17.31it/s, loss=99.756]\n","- Train loss : 99.756\n","- Train teacher loss : 0.151\n","- Train adversarial loss : 9.869\n","- Eval metrics : acc: 92.850 ; loss: 0.323\n","- New best model \n","- So far best epoch: 92, best acc: 92.850\n","Epoch 93/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:22<00:00, 17.31it/s, loss=99.754]\n","- Train loss : 99.754\n","- Train teacher loss : 0.150\n","- Train adversarial loss : 9.890\n","- Eval metrics : acc: 92.108 ; loss: 0.360\n","- So far best epoch: 92, best acc: 92.850\n","Epoch 94/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:22<00:00, 17.28it/s, loss=99.752]\n","- Train loss : 99.752\n","- Train teacher loss : 0.149\n","- Train adversarial loss : 9.917\n","- Eval metrics : acc: 92.761 ; loss: 0.357\n","- So far best epoch: 92, best acc: 92.850\n","Epoch 95/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:22<00:00, 17.30it/s, loss=99.750]\n","- Train loss : 99.750\n","- Train teacher loss : 0.147\n","- Train adversarial loss : 9.921\n","- Eval metrics : acc: 92.435 ; loss: 0.364\n","- So far best epoch: 92, best acc: 92.850\n","Epoch 96/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:22<00:00, 17.29it/s, loss=99.753]\n","- Train loss : 99.753\n","- Train teacher loss : 0.150\n","- Train adversarial loss : 9.919\n","- Eval metrics : acc: 92.296 ; loss: 0.346\n","- So far best epoch: 92, best acc: 92.850\n","Epoch 97/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:22<00:00, 17.31it/s, loss=99.747]\n","- Train loss : 99.747\n","- Train teacher loss : 0.145\n","- Train adversarial loss : 9.950\n","- Eval metrics : acc: 92.840 ; loss: 0.347\n","- So far best epoch: 92, best acc: 92.850\n","Epoch 98/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:22<00:00, 17.31it/s, loss=99.750]\n","- Train loss : 99.750\n","- Train teacher loss : 0.147\n","- Train adversarial loss : 9.945\n","- Eval metrics : acc: 92.563 ; loss: 0.364\n","- So far best epoch: 92, best acc: 92.850\n","Epoch 99/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:22<00:00, 17.35it/s, loss=99.754]\n","- Train loss : 99.754\n","- Train teacher loss : 0.151\n","- Train adversarial loss : 9.927\n","- Eval metrics : acc: 92.316 ; loss: 0.435\n","- So far best epoch: 92, best acc: 92.850\n","Epoch 100/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:22<00:00, 17.33it/s, loss=99.748]\n","- Train loss : 99.748\n","- Train teacher loss : 0.144\n","- Train adversarial loss : 9.919\n","- Eval metrics : acc: 92.019 ; loss: 0.409\n","- So far best epoch: 92, best acc: 92.850\n","Epoch 101/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:22<00:00, 17.33it/s, loss=99.745]\n","- Train loss : 99.745\n","- Train teacher loss : 0.143\n","- Train adversarial loss : 9.959\n","- Eval metrics : acc: 91.950 ; loss: 0.410\n","- So far best epoch: 92, best acc: 92.850\n","Epoch 102/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:22<00:00, 17.33it/s, loss=99.748]\n","- Train loss : 99.748\n","- Train teacher loss : 0.145\n","- Train adversarial loss : 9.936\n","- Eval metrics : acc: 92.227 ; loss: 0.412\n","- So far best epoch: 92, best acc: 92.850\n","Epoch 103/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:22<00:00, 17.31it/s, loss=99.740]\n","- Train loss : 99.740\n","- Train teacher loss : 0.138\n","- Train adversarial loss : 9.945\n","- Eval metrics : acc: 92.178 ; loss: 0.414\n","- So far best epoch: 92, best acc: 92.850\n","Epoch 104/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:22<00:00, 17.34it/s, loss=99.748]\n","- Train loss : 99.748\n","- Train teacher loss : 0.146\n","- Train adversarial loss : 9.950\n","- Eval metrics : acc: 92.247 ; loss: 0.391\n","- So far best epoch: 92, best acc: 92.850\n","Epoch 105/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:22<00:00, 17.33it/s, loss=99.751]\n","- Train loss : 99.751\n","- Train teacher loss : 0.150\n","- Train adversarial loss : 9.962\n","- Eval metrics : acc: 92.207 ; loss: 0.395\n","- So far best epoch: 92, best acc: 92.850\n","Epoch 106/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:22<00:00, 17.31it/s, loss=99.746]\n","- Train loss : 99.746\n","- Train teacher loss : 0.145\n","- Train adversarial loss : 9.966\n","- Eval metrics : acc: 92.039 ; loss: 0.406\n","- So far best epoch: 92, best acc: 92.850\n","Epoch 107/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:22<00:00, 17.36it/s, loss=99.755]\n","- Train loss : 99.755\n","- Train teacher loss : 0.153\n","- Train adversarial loss : 9.949\n","- Eval metrics : acc: 91.297 ; loss: 0.445\n","- So far best epoch: 92, best acc: 92.850\n","Epoch 108/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:22<00:00, 17.36it/s, loss=99.749]\n","- Train loss : 99.749\n","- Train teacher loss : 0.148\n","- Train adversarial loss : 9.959\n","- Eval metrics : acc: 92.286 ; loss: 0.416\n","- So far best epoch: 92, best acc: 92.850\n","Epoch 109/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:22<00:00, 17.37it/s, loss=99.756]\n","- Train loss : 99.756\n","- Train teacher loss : 0.152\n","- Train adversarial loss : 9.913\n","- Eval metrics : acc: 92.009 ; loss: 0.384\n","- So far best epoch: 92, best acc: 92.850\n","Epoch 110/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:22<00:00, 17.30it/s, loss=99.750]\n","- Train loss : 99.750\n","- Train teacher loss : 0.148\n","- Train adversarial loss : 9.944\n","- Eval metrics : acc: 92.247 ; loss: 0.366\n","- So far best epoch: 92, best acc: 92.850\n","Epoch 111/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:22<00:00, 17.33it/s, loss=99.753]\n","- Train loss : 99.753\n","- Train teacher loss : 0.150\n","- Train adversarial loss : 9.940\n","- Eval metrics : acc: 91.396 ; loss: 0.434\n","- So far best epoch: 92, best acc: 92.850\n","Epoch 112/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:22<00:00, 17.34it/s, loss=99.748]\n","- Train loss : 99.748\n","- Train teacher loss : 0.145\n","- Train adversarial loss : 9.934\n","- Eval metrics : acc: 91.901 ; loss: 0.399\n","- So far best epoch: 92, best acc: 92.850\n","Epoch 113/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:22<00:00, 17.33it/s, loss=99.750]\n","- Train loss : 99.750\n","- Train teacher loss : 0.147\n","- Train adversarial loss : 9.914\n","- Eval metrics : acc: 92.069 ; loss: 0.380\n","- So far best epoch: 92, best acc: 92.850\n","Epoch 114/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:22<00:00, 17.40it/s, loss=99.750]\n","- Train loss : 99.750\n","- Train teacher loss : 0.147\n","- Train adversarial loss : 9.949\n","- Eval metrics : acc: 87.381 ; loss: 0.602\n","- So far best epoch: 92, best acc: 92.850\n","Epoch 115/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:22<00:00, 17.36it/s, loss=99.751]\n","- Train loss : 99.751\n","- Train teacher loss : 0.148\n","- Train adversarial loss : 9.934\n","- Eval metrics : acc: 92.672 ; loss: 0.361\n","- So far best epoch: 92, best acc: 92.850\n","Epoch 116/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:22<00:00, 17.34it/s, loss=99.755]\n","- Train loss : 99.755\n","- Train teacher loss : 0.152\n","- Train adversarial loss : 9.919\n","- Eval metrics : acc: 91.525 ; loss: 0.381\n","- So far best epoch: 92, best acc: 92.850\n","Epoch 117/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:22<00:00, 17.34it/s, loss=99.750]\n","- Train loss : 99.750\n","- Train teacher loss : 0.148\n","- Train adversarial loss : 9.947\n","- Eval metrics : acc: 91.347 ; loss: 0.461\n","- So far best epoch: 92, best acc: 92.850\n","Epoch 118/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:22<00:00, 17.33it/s, loss=99.755]\n","- Train loss : 99.755\n","- Train teacher loss : 0.154\n","- Train adversarial loss : 9.966\n","- Eval metrics : acc: 90.081 ; loss: 0.488\n","- So far best epoch: 92, best acc: 92.850\n","Epoch 119/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:22<00:00, 17.32it/s, loss=99.760]\n","- Train loss : 99.760\n","- Train teacher loss : 0.156\n","- Train adversarial loss : 9.911\n","- Eval metrics : acc: 91.288 ; loss: 0.421\n","- So far best epoch: 92, best acc: 92.850\n","Epoch 120/160\n","Learning Rate 0.010000000000000002\n","100% 391/391 [00:22<00:00, 17.33it/s, loss=99.749]\n","- Train loss : 99.749\n","- Train teacher loss : 0.146\n","- Train adversarial loss : 9.916\n","- Eval metrics : acc: 91.802 ; loss: 0.443\n","- So far best epoch: 92, best acc: 92.850\n","Epoch 121/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:22<00:00, 17.34it/s, loss=99.708]\n","- Train loss : 99.708\n","- Train teacher loss : 0.106\n","- Train adversarial loss : 9.956\n","- Eval metrics : acc: 93.740 ; loss: 0.355\n","- New best model \n","- So far best epoch: 121, best acc: 93.740\n","Epoch 122/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:22<00:00, 17.33it/s, loss=99.691]\n","- Train loss : 99.691\n","- Train teacher loss : 0.093\n","- Train adversarial loss : 10.037\n","- Eval metrics : acc: 93.898 ; loss: 0.354\n","- New best model \n","- So far best epoch: 122, best acc: 93.898\n","Epoch 123/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:22<00:00, 17.32it/s, loss=99.685]\n","- Train loss : 99.685\n","- Train teacher loss : 0.088\n","- Train adversarial loss : 10.087\n","- Eval metrics : acc: 93.681 ; loss: 0.388\n","- So far best epoch: 122, best acc: 93.898\n","Epoch 124/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:22<00:00, 17.31it/s, loss=99.683]\n","- Train loss : 99.683\n","- Train teacher loss : 0.087\n","- Train adversarial loss : 10.103\n","- Eval metrics : acc: 93.859 ; loss: 0.385\n","- So far best epoch: 122, best acc: 93.898\n","Epoch 125/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:22<00:00, 17.32it/s, loss=99.677]\n","- Train loss : 99.677\n","- Train teacher loss : 0.083\n","- Train adversarial loss : 10.133\n","- Eval metrics : acc: 93.987 ; loss: 0.393\n","- New best model \n","- So far best epoch: 125, best acc: 93.987\n","Epoch 126/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:22<00:00, 17.34it/s, loss=99.673]\n","- Train loss : 99.673\n","- Train teacher loss : 0.079\n","- Train adversarial loss : 10.148\n","- Eval metrics : acc: 93.859 ; loss: 0.401\n","- So far best epoch: 125, best acc: 93.987\n","Epoch 127/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:22<00:00, 17.31it/s, loss=99.673]\n","- Train loss : 99.673\n","- Train teacher loss : 0.080\n","- Train adversarial loss : 10.158\n","- Eval metrics : acc: 93.829 ; loss: 0.400\n","- So far best epoch: 125, best acc: 93.987\n","Epoch 128/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:22<00:00, 17.33it/s, loss=99.670]\n","- Train loss : 99.670\n","- Train teacher loss : 0.077\n","- Train adversarial loss : 10.168\n","- Eval metrics : acc: 94.076 ; loss: 0.407\n","- New best model \n","- So far best epoch: 128, best acc: 94.076\n","Epoch 129/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:22<00:00, 17.32it/s, loss=99.669]\n","- Train loss : 99.669\n","- Train teacher loss : 0.076\n","- Train adversarial loss : 10.186\n","- Eval metrics : acc: 93.879 ; loss: 0.417\n","- So far best epoch: 128, best acc: 94.076\n","Epoch 130/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:22<00:00, 17.33it/s, loss=99.669]\n","- Train loss : 99.669\n","- Train teacher loss : 0.077\n","- Train adversarial loss : 10.193\n","- Eval metrics : acc: 93.908 ; loss: 0.413\n","- So far best epoch: 128, best acc: 94.076\n","Epoch 131/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:22<00:00, 17.33it/s, loss=99.668]\n","- Train loss : 99.668\n","- Train teacher loss : 0.076\n","- Train adversarial loss : 10.194\n","- Eval metrics : acc: 93.997 ; loss: 0.413\n","- So far best epoch: 128, best acc: 94.076\n","Epoch 132/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:22<00:00, 17.32it/s, loss=99.668]\n","- Train loss : 99.668\n","- Train teacher loss : 0.076\n","- Train adversarial loss : 10.212\n","- Eval metrics : acc: 93.977 ; loss: 0.418\n","- So far best epoch: 128, best acc: 94.076\n","Epoch 133/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:22<00:00, 17.34it/s, loss=99.667]\n","- Train loss : 99.667\n","- Train teacher loss : 0.075\n","- Train adversarial loss : 10.206\n","- Eval metrics : acc: 94.106 ; loss: 0.411\n","- New best model \n","- So far best epoch: 133, best acc: 94.106\n","Epoch 134/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:22<00:00, 17.33it/s, loss=99.665]\n","- Train loss : 99.665\n","- Train teacher loss : 0.073\n","- Train adversarial loss : 10.204\n","- Eval metrics : acc: 94.076 ; loss: 0.406\n","- So far best epoch: 133, best acc: 94.106\n","Epoch 135/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:22<00:00, 17.29it/s, loss=99.665]\n","- Train loss : 99.665\n","- Train teacher loss : 0.073\n","- Train adversarial loss : 10.223\n","- Eval metrics : acc: 93.977 ; loss: 0.436\n","- So far best epoch: 133, best acc: 94.106\n","Epoch 136/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:22<00:00, 17.31it/s, loss=99.665]\n","- Train loss : 99.665\n","- Train teacher loss : 0.074\n","- Train adversarial loss : 10.226\n","- Eval metrics : acc: 94.037 ; loss: 0.435\n","- So far best epoch: 133, best acc: 94.106\n","Epoch 137/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:22<00:00, 17.32it/s, loss=99.664]\n","- Train loss : 99.664\n","- Train teacher loss : 0.073\n","- Train adversarial loss : 10.227\n","- Eval metrics : acc: 93.928 ; loss: 0.438\n","- So far best epoch: 133, best acc: 94.106\n","Epoch 138/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:22<00:00, 17.31it/s, loss=99.663]\n","- Train loss : 99.663\n","- Train teacher loss : 0.072\n","- Train adversarial loss : 10.231\n","- Eval metrics : acc: 93.740 ; loss: 0.438\n","- So far best epoch: 133, best acc: 94.106\n","Epoch 139/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:22<00:00, 17.32it/s, loss=99.663]\n","- Train loss : 99.663\n","- Train teacher loss : 0.072\n","- Train adversarial loss : 10.232\n","- Eval metrics : acc: 94.096 ; loss: 0.429\n","- So far best epoch: 133, best acc: 94.106\n","Epoch 140/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:22<00:00, 17.33it/s, loss=99.662]\n","- Train loss : 99.662\n","- Train teacher loss : 0.072\n","- Train adversarial loss : 10.235\n","- Eval metrics : acc: 94.106 ; loss: 0.426\n","- New best model \n","- So far best epoch: 140, best acc: 94.106\n","Epoch 141/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:22<00:00, 17.32it/s, loss=99.663]\n","- Train loss : 99.663\n","- Train teacher loss : 0.073\n","- Train adversarial loss : 10.239\n","- Eval metrics : acc: 93.928 ; loss: 0.444\n","- So far best epoch: 140, best acc: 94.106\n","Epoch 142/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:22<00:00, 17.33it/s, loss=99.662]\n","- Train loss : 99.662\n","- Train teacher loss : 0.071\n","- Train adversarial loss : 10.247\n","- Eval metrics : acc: 94.096 ; loss: 0.435\n","- So far best epoch: 140, best acc: 94.106\n","Epoch 143/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:22<00:00, 17.33it/s, loss=99.661]\n","- Train loss : 99.661\n","- Train teacher loss : 0.071\n","- Train adversarial loss : 10.247\n","- Eval metrics : acc: 94.106 ; loss: 0.430\n","- New best model \n","- So far best epoch: 143, best acc: 94.106\n","Epoch 144/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:22<00:00, 17.33it/s, loss=99.661]\n","- Train loss : 99.661\n","- Train teacher loss : 0.071\n","- Train adversarial loss : 10.262\n","- Eval metrics : acc: 94.116 ; loss: 0.422\n","- New best model \n","- So far best epoch: 144, best acc: 94.116\n","Epoch 145/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:22<00:00, 17.30it/s, loss=99.659]\n","- Train loss : 99.659\n","- Train teacher loss : 0.069\n","- Train adversarial loss : 10.254\n","- Eval metrics : acc: 94.136 ; loss: 0.444\n","- New best model \n","- So far best epoch: 145, best acc: 94.136\n","Epoch 146/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:22<00:00, 17.31it/s, loss=99.659]\n","- Train loss : 99.659\n","- Train teacher loss : 0.070\n","- Train adversarial loss : 10.254\n","- Eval metrics : acc: 94.126 ; loss: 0.458\n","- So far best epoch: 145, best acc: 94.136\n","Epoch 147/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:22<00:00, 17.31it/s, loss=99.660]\n","- Train loss : 99.660\n","- Train teacher loss : 0.071\n","- Train adversarial loss : 10.259\n","- Eval metrics : acc: 94.185 ; loss: 0.439\n","- New best model \n","- So far best epoch: 147, best acc: 94.185\n","Epoch 148/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:22<00:00, 17.34it/s, loss=99.658]\n","- Train loss : 99.658\n","- Train teacher loss : 0.069\n","- Train adversarial loss : 10.274\n","- Eval metrics : acc: 94.047 ; loss: 0.455\n","- So far best epoch: 147, best acc: 94.185\n","Epoch 149/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:22<00:00, 17.33it/s, loss=99.657]\n","- Train loss : 99.657\n","- Train teacher loss : 0.068\n","- Train adversarial loss : 10.270\n","- Eval metrics : acc: 94.126 ; loss: 0.456\n","- So far best epoch: 147, best acc: 94.185\n","Epoch 150/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:22<00:00, 17.32it/s, loss=99.657]\n","- Train loss : 99.657\n","- Train teacher loss : 0.068\n","- Train adversarial loss : 10.270\n","- Eval metrics : acc: 94.284 ; loss: 0.436\n","- New best model \n","- So far best epoch: 150, best acc: 94.284\n","Epoch 151/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:22<00:00, 17.34it/s, loss=99.658]\n","- Train loss : 99.658\n","- Train teacher loss : 0.069\n","- Train adversarial loss : 10.274\n","- Eval metrics : acc: 94.235 ; loss: 0.425\n","- So far best epoch: 150, best acc: 94.284\n","Epoch 152/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:22<00:00, 17.33it/s, loss=99.658]\n","- Train loss : 99.658\n","- Train teacher loss : 0.069\n","- Train adversarial loss : 10.275\n","- Eval metrics : acc: 94.076 ; loss: 0.446\n","- So far best epoch: 150, best acc: 94.284\n","Epoch 153/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:22<00:00, 17.34it/s, loss=99.658]\n","- Train loss : 99.658\n","- Train teacher loss : 0.069\n","- Train adversarial loss : 10.273\n","- Eval metrics : acc: 94.195 ; loss: 0.438\n","- So far best epoch: 150, best acc: 94.284\n","Epoch 154/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:22<00:00, 17.34it/s, loss=99.657]\n","- Train loss : 99.657\n","- Train teacher loss : 0.068\n","- Train adversarial loss : 10.273\n","- Eval metrics : acc: 94.076 ; loss: 0.439\n","- So far best epoch: 150, best acc: 94.284\n","Epoch 155/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:22<00:00, 17.33it/s, loss=99.658]\n","- Train loss : 99.658\n","- Train teacher loss : 0.069\n","- Train adversarial loss : 10.277\n","- Eval metrics : acc: 94.116 ; loss: 0.459\n","- So far best epoch: 150, best acc: 94.284\n","Epoch 156/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:22<00:00, 17.32it/s, loss=99.657]\n","- Train loss : 99.657\n","- Train teacher loss : 0.068\n","- Train adversarial loss : 10.273\n","- Eval metrics : acc: 94.264 ; loss: 0.439\n","- So far best epoch: 150, best acc: 94.284\n","Epoch 157/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:22<00:00, 17.32it/s, loss=99.657]\n","- Train loss : 99.657\n","- Train teacher loss : 0.068\n","- Train adversarial loss : 10.286\n","- Eval metrics : acc: 94.284 ; loss: 0.446\n","- New best model \n","- So far best epoch: 157, best acc: 94.284\n","Epoch 158/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:22<00:00, 17.32it/s, loss=99.658]\n","- Train loss : 99.658\n","- Train teacher loss : 0.069\n","- Train adversarial loss : 10.290\n","- Eval metrics : acc: 94.254 ; loss: 0.448\n","- So far best epoch: 157, best acc: 94.284\n","Epoch 159/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:22<00:00, 17.32it/s, loss=99.655]\n","- Train loss : 99.655\n","- Train teacher loss : 0.067\n","- Train adversarial loss : 10.287\n","- Eval metrics : acc: 94.126 ; loss: 0.447\n","- So far best epoch: 157, best acc: 94.284\n","Epoch 160/160\n","Learning Rate 0.0010000000000000002\n","100% 391/391 [00:22<00:00, 17.33it/s, loss=99.656]\n","- Train loss : 99.656\n","- Train teacher loss : 0.067\n","- Train adversarial loss : 10.290\n","- Eval metrics : acc: 94.304 ; loss: 0.449\n","- New best model \n","- So far best epoch: 160, best acc: 94.304\n"]}],"source":["!python train_nasty.py --save_path experiments/CIFAR10/kd_nasty_resnet18/nasty_resnet18"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"VCfWsBMvyuCF","outputId":"724b741a-ca26-4bb7-ee76-7b272c492452"},"outputs":[{"name":"stdout","output_type":"stream","text":["model_name:net\n","num_channels:32\n","dropout_rate:0.0\n","learning_rate:0.001\n","schedule:[999]\n","gamma:0.1\n","batch_size:128\n","num_epochs:100\n","num_workers:4\n","augmentation:1\n","cuda:True\n","dataset:cifar10\n","teacher_model:resnet18\n","teacher_resume:experiments/CIFAR10/kd_nasty_resnet18/nasty_resnet18/best_model.tar\n","temperature:4\n","alpha:0.9\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Number of class: 10\n","Create Student Model --- net\n","Create Teacher Model --- resnet18\n","- Train from scratch \n","- Load Trained teacher model from experiments/CIFAR10/kd_nasty_resnet18/nasty_resnet18/best_model.tar\n","Optimizer: Adam\n","- Teacher Model Evaluation ....\n","- Teacher Model Eval metrics : acc: 94.304 ; loss: 0.449\n","Epoch 1/100\n","Learning Rate 0.001\n","100% 391/391 [00:07<00:00, 53.96it/s, loss=10.206]\n","- Train loss : 10.206\n","- Eval metrics : acc: 53.293 ; loss: 2.178\n","- New best model \n","- So far best epoch: 1, best acc: 53.293\n","Epoch 2/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.76it/s, loss=6.904]\n","- Train loss : 6.904\n","- Eval metrics : acc: 58.445 ; loss: 2.003\n","- New best model \n","- So far best epoch: 2, best acc: 58.445\n","Epoch 3/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.58it/s, loss=6.035]\n","- Train loss : 6.035\n","- Eval metrics : acc: 65.022 ; loss: 1.571\n","- New best model \n","- So far best epoch: 3, best acc: 65.022\n","Epoch 4/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.92it/s, loss=5.482]\n","- Train loss : 5.482\n","- Eval metrics : acc: 66.594 ; loss: 1.585\n","- New best model \n","- So far best epoch: 4, best acc: 66.594\n","Epoch 5/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.25it/s, loss=5.053]\n","- Train loss : 5.053\n","- Eval metrics : acc: 67.929 ; loss: 1.527\n","- New best model \n","- So far best epoch: 5, best acc: 67.929\n","Epoch 6/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.45it/s, loss=4.801]\n","- Train loss : 4.801\n","- Eval metrics : acc: 70.955 ; loss: 1.300\n","- New best model \n","- So far best epoch: 6, best acc: 70.955\n","Epoch 7/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.08it/s, loss=4.547]\n","- Train loss : 4.547\n","- Eval metrics : acc: 71.005 ; loss: 1.364\n","- New best model \n","- So far best epoch: 7, best acc: 71.005\n","Epoch 8/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.30it/s, loss=4.380]\n","- Train loss : 4.380\n","- Eval metrics : acc: 73.081 ; loss: 1.241\n","- New best model \n","- So far best epoch: 8, best acc: 73.081\n","Epoch 9/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.66it/s, loss=4.220]\n","- Train loss : 4.220\n","- Eval metrics : acc: 73.151 ; loss: 1.231\n","- New best model \n","- So far best epoch: 9, best acc: 73.151\n","Epoch 10/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.00it/s, loss=4.036]\n","- Train loss : 4.036\n","- Eval metrics : acc: 74.832 ; loss: 1.162\n","- New best model \n","- So far best epoch: 10, best acc: 74.832\n","Epoch 11/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.03it/s, loss=3.897]\n","- Train loss : 3.897\n","- Eval metrics : acc: 73.240 ; loss: 1.176\n","- So far best epoch: 10, best acc: 74.832\n","Epoch 12/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.21it/s, loss=3.806]\n","- Train loss : 3.806\n","- Eval metrics : acc: 74.239 ; loss: 1.202\n","- So far best epoch: 10, best acc: 74.832\n","Epoch 13/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.11it/s, loss=3.618]\n","- Train loss : 3.618\n","- Eval metrics : acc: 75.524 ; loss: 1.197\n","- New best model \n","- So far best epoch: 13, best acc: 75.524\n","Epoch 14/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.18it/s, loss=3.517]\n","- Train loss : 3.517\n","- Eval metrics : acc: 75.485 ; loss: 1.206\n","- So far best epoch: 13, best acc: 75.524\n","Epoch 15/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.05it/s, loss=3.467]\n","- Train loss : 3.467\n","- Eval metrics : acc: 75.979 ; loss: 1.132\n","- New best model \n","- So far best epoch: 15, best acc: 75.979\n","Epoch 16/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.85it/s, loss=3.414]\n","- Train loss : 3.414\n","- Eval metrics : acc: 76.612 ; loss: 1.149\n","- New best model \n","- So far best epoch: 16, best acc: 76.612\n","Epoch 17/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.44it/s, loss=3.324]\n","- Train loss : 3.324\n","- Eval metrics : acc: 75.297 ; loss: 1.262\n","- So far best epoch: 16, best acc: 76.612\n","Epoch 18/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.81it/s, loss=3.219]\n","- Train loss : 3.219\n","- Eval metrics : acc: 77.176 ; loss: 1.157\n","- New best model \n","- So far best epoch: 18, best acc: 77.176\n","Epoch 19/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.32it/s, loss=3.151]\n","- Train loss : 3.151\n","- Eval metrics : acc: 75.949 ; loss: 1.243\n","- So far best epoch: 18, best acc: 77.176\n","Epoch 20/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.27it/s, loss=3.104]\n","- Train loss : 3.104\n","- Eval metrics : acc: 78.590 ; loss: 1.024\n","- New best model \n","- So far best epoch: 20, best acc: 78.590\n","Epoch 21/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.08it/s, loss=3.005]\n","- Train loss : 3.005\n","- Eval metrics : acc: 77.324 ; loss: 1.134\n","- So far best epoch: 20, best acc: 78.590\n","Epoch 22/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.65it/s, loss=2.978]\n","- Train loss : 2.978\n","- Eval metrics : acc: 78.066 ; loss: 1.098\n","- So far best epoch: 20, best acc: 78.590\n","Epoch 23/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.14it/s, loss=2.897]\n","- Train loss : 2.897\n","- Eval metrics : acc: 78.105 ; loss: 1.093\n","- So far best epoch: 20, best acc: 78.590\n","Epoch 24/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.72it/s, loss=2.872]\n","- Train loss : 2.872\n","- Eval metrics : acc: 77.304 ; loss: 1.229\n","- So far best epoch: 20, best acc: 78.590\n","Epoch 25/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.61it/s, loss=2.847]\n","- Train loss : 2.847\n","- Eval metrics : acc: 78.926 ; loss: 1.018\n","- New best model \n","- So far best epoch: 25, best acc: 78.926\n","Epoch 26/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.77it/s, loss=2.726]\n","- Train loss : 2.726\n","- Eval metrics : acc: 79.213 ; loss: 0.997\n","- New best model \n","- So far best epoch: 26, best acc: 79.213\n","Epoch 27/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.58it/s, loss=2.710]\n","- Train loss : 2.710\n","- Eval metrics : acc: 78.135 ; loss: 1.105\n","- So far best epoch: 26, best acc: 79.213\n","Epoch 28/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.24it/s, loss=2.697]\n","- Train loss : 2.697\n","- Eval metrics : acc: 78.837 ; loss: 1.092\n","- So far best epoch: 26, best acc: 79.213\n","Epoch 29/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.42it/s, loss=2.687]\n","- Train loss : 2.687\n","- Eval metrics : acc: 78.481 ; loss: 1.071\n","- So far best epoch: 26, best acc: 79.213\n","Epoch 30/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.05it/s, loss=2.597]\n","- Train loss : 2.597\n","- Eval metrics : acc: 78.975 ; loss: 1.097\n","- So far best epoch: 26, best acc: 79.213\n","Epoch 31/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.34it/s, loss=2.593]\n","- Train loss : 2.593\n","- Eval metrics : acc: 78.422 ; loss: 1.108\n","- So far best epoch: 26, best acc: 79.213\n","Epoch 32/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.27it/s, loss=2.542]\n","- Train loss : 2.542\n","- Eval metrics : acc: 78.926 ; loss: 1.105\n","- So far best epoch: 26, best acc: 79.213\n","Epoch 33/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.93it/s, loss=2.484]\n","- Train loss : 2.484\n","- Eval metrics : acc: 78.639 ; loss: 1.079\n","- So far best epoch: 26, best acc: 79.213\n","Epoch 34/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.83it/s, loss=2.462]\n","- Train loss : 2.462\n","- Eval metrics : acc: 78.283 ; loss: 1.147\n","- So far best epoch: 26, best acc: 79.213\n","Epoch 35/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.34it/s, loss=2.419]\n","- Train loss : 2.419\n","- Eval metrics : acc: 79.480 ; loss: 1.025\n","- New best model \n","- So far best epoch: 35, best acc: 79.480\n","Epoch 36/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.29it/s, loss=2.386]\n","- Train loss : 2.386\n","- Eval metrics : acc: 79.203 ; loss: 1.078\n","- So far best epoch: 35, best acc: 79.480\n","Epoch 37/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.16it/s, loss=2.371]\n","- Train loss : 2.371\n","- Eval metrics : acc: 79.411 ; loss: 1.045\n","- So far best epoch: 35, best acc: 79.480\n","Epoch 38/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.64it/s, loss=2.379]\n","- Train loss : 2.379\n","- Eval metrics : acc: 78.886 ; loss: 1.129\n","- So far best epoch: 35, best acc: 79.480\n","Epoch 39/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.57it/s, loss=2.310]\n","- Train loss : 2.310\n","- Eval metrics : acc: 80.281 ; loss: 0.977\n","- New best model \n","- So far best epoch: 39, best acc: 80.281\n","Epoch 40/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.89it/s, loss=2.255]\n","- Train loss : 2.255\n","- Eval metrics : acc: 79.945 ; loss: 1.010\n","- So far best epoch: 39, best acc: 80.281\n","Epoch 41/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.22it/s, loss=2.250]\n","- Train loss : 2.250\n","- Eval metrics : acc: 79.915 ; loss: 1.040\n","- So far best epoch: 39, best acc: 80.281\n","Epoch 42/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.41it/s, loss=2.239]\n","- Train loss : 2.239\n","- Eval metrics : acc: 80.261 ; loss: 1.039\n","- So far best epoch: 39, best acc: 80.281\n","Epoch 43/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.57it/s, loss=2.204]\n","- Train loss : 2.204\n","- Eval metrics : acc: 79.480 ; loss: 1.055\n","- So far best epoch: 39, best acc: 80.281\n","Epoch 44/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.57it/s, loss=2.178]\n","- Train loss : 2.178\n","- Eval metrics : acc: 79.747 ; loss: 1.009\n","- So far best epoch: 39, best acc: 80.281\n","Epoch 45/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.19it/s, loss=2.140]\n","- Train loss : 2.140\n","- Eval metrics : acc: 79.846 ; loss: 1.050\n","- So far best epoch: 39, best acc: 80.281\n","Epoch 46/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.75it/s, loss=2.121]\n","- Train loss : 2.121\n","- Eval metrics : acc: 79.312 ; loss: 1.047\n","- So far best epoch: 39, best acc: 80.281\n","Epoch 47/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.90it/s, loss=2.111]\n","- Train loss : 2.111\n","- Eval metrics : acc: 80.558 ; loss: 0.997\n","- New best model \n","- So far best epoch: 47, best acc: 80.558\n","Epoch 48/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.20it/s, loss=2.074]\n","- Train loss : 2.074\n","- Eval metrics : acc: 81.290 ; loss: 0.963\n","- New best model \n","- So far best epoch: 48, best acc: 81.290\n","Epoch 49/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.44it/s, loss=2.064]\n","- Train loss : 2.064\n","- Eval metrics : acc: 79.579 ; loss: 1.070\n","- So far best epoch: 48, best acc: 81.290\n","Epoch 50/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.52it/s, loss=1.992]\n","- Train loss : 1.992\n","- Eval metrics : acc: 79.796 ; loss: 1.102\n","- So far best epoch: 48, best acc: 81.290\n","Epoch 51/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.49it/s, loss=2.032]\n","- Train loss : 2.032\n","- Eval metrics : acc: 81.102 ; loss: 0.958\n","- So far best epoch: 48, best acc: 81.290\n","Epoch 52/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.33it/s, loss=2.023]\n","- Train loss : 2.023\n","- Eval metrics : acc: 79.292 ; loss: 1.115\n","- So far best epoch: 48, best acc: 81.290\n","Epoch 53/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.01it/s, loss=1.978]\n","- Train loss : 1.978\n","- Eval metrics : acc: 79.816 ; loss: 1.097\n","- So far best epoch: 48, best acc: 81.290\n","Epoch 54/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.13it/s, loss=2.005]\n","- Train loss : 2.005\n","- Eval metrics : acc: 79.885 ; loss: 1.071\n","- So far best epoch: 48, best acc: 81.290\n","Epoch 55/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.97it/s, loss=1.945]\n","- Train loss : 1.945\n","- Eval metrics : acc: 80.894 ; loss: 1.041\n","- So far best epoch: 48, best acc: 81.290\n","Epoch 56/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.39it/s, loss=1.962]\n","- Train loss : 1.962\n","- Eval metrics : acc: 81.151 ; loss: 0.996\n","- So far best epoch: 48, best acc: 81.290\n","Epoch 57/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.24it/s, loss=1.913]\n","- Train loss : 1.913\n","- Eval metrics : acc: 79.945 ; loss: 1.062\n","- So far best epoch: 48, best acc: 81.290\n","Epoch 58/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.40it/s, loss=1.908]\n","- Train loss : 1.908\n","- Eval metrics : acc: 80.686 ; loss: 1.015\n","- So far best epoch: 48, best acc: 81.290\n","Epoch 59/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.67it/s, loss=1.905]\n","- Train loss : 1.905\n","- Eval metrics : acc: 81.121 ; loss: 0.999\n","- So far best epoch: 48, best acc: 81.290\n","Epoch 60/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.80it/s, loss=1.913]\n","- Train loss : 1.913\n","- Eval metrics : acc: 81.240 ; loss: 0.981\n","- So far best epoch: 48, best acc: 81.290\n","Epoch 61/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.09it/s, loss=1.866]\n","- Train loss : 1.866\n","- Eval metrics : acc: 80.133 ; loss: 1.107\n","- So far best epoch: 48, best acc: 81.290\n","Epoch 62/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.38it/s, loss=1.872]\n","- Train loss : 1.872\n","- Eval metrics : acc: 80.805 ; loss: 1.019\n","- So far best epoch: 48, best acc: 81.290\n","Epoch 63/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.43it/s, loss=1.880]\n","- Train loss : 1.880\n","- Eval metrics : acc: 80.845 ; loss: 1.038\n","- So far best epoch: 48, best acc: 81.290\n","Epoch 64/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.41it/s, loss=1.800]\n","- Train loss : 1.800\n","- Eval metrics : acc: 80.736 ; loss: 1.047\n","- So far best epoch: 48, best acc: 81.290\n","Epoch 65/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 60.99it/s, loss=1.805]\n","- Train loss : 1.805\n","- Eval metrics : acc: 80.884 ; loss: 1.072\n","- So far best epoch: 48, best acc: 81.290\n","Epoch 66/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.26it/s, loss=1.823]\n","- Train loss : 1.823\n","- Eval metrics : acc: 81.329 ; loss: 1.012\n","- New best model \n","- So far best epoch: 66, best acc: 81.329\n","Epoch 67/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.03it/s, loss=1.771]\n","- Train loss : 1.771\n","- Eval metrics : acc: 81.032 ; loss: 1.070\n","- So far best epoch: 66, best acc: 81.329\n","Epoch 68/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.39it/s, loss=1.793]\n","- Train loss : 1.793\n","- Eval metrics : acc: 81.784 ; loss: 0.979\n","- New best model \n","- So far best epoch: 68, best acc: 81.784\n","Epoch 69/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.31it/s, loss=1.762]\n","- Train loss : 1.762\n","- Eval metrics : acc: 80.647 ; loss: 1.062\n","- So far best epoch: 68, best acc: 81.784\n","Epoch 70/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.31it/s, loss=1.740]\n","- Train loss : 1.740\n","- Eval metrics : acc: 81.092 ; loss: 1.019\n","- So far best epoch: 68, best acc: 81.784\n","Epoch 71/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.32it/s, loss=1.740]\n","- Train loss : 1.740\n","- Eval metrics : acc: 80.548 ; loss: 1.127\n","- So far best epoch: 68, best acc: 81.784\n","Epoch 72/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.55it/s, loss=1.759]\n","- Train loss : 1.759\n","- Eval metrics : acc: 79.826 ; loss: 1.158\n","- So far best epoch: 68, best acc: 81.784\n","Epoch 73/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.72it/s, loss=1.709]\n","- Train loss : 1.709\n","- Eval metrics : acc: 81.141 ; loss: 1.007\n","- So far best epoch: 68, best acc: 81.784\n","Epoch 74/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.31it/s, loss=1.676]\n","- Train loss : 1.676\n","- Eval metrics : acc: 82.486 ; loss: 0.950\n","- New best model \n","- So far best epoch: 74, best acc: 82.486\n","Epoch 75/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.48it/s, loss=1.659]\n","- Train loss : 1.659\n","- Eval metrics : acc: 81.873 ; loss: 1.003\n","- So far best epoch: 74, best acc: 82.486\n","Epoch 76/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.58it/s, loss=1.669]\n","- Train loss : 1.669\n","- Eval metrics : acc: 81.468 ; loss: 1.053\n","- So far best epoch: 74, best acc: 82.486\n","Epoch 77/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 60.67it/s, loss=1.681]\n","- Train loss : 1.681\n","- Eval metrics : acc: 80.498 ; loss: 1.092\n","- So far best epoch: 74, best acc: 82.486\n","Epoch 78/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.24it/s, loss=1.625]\n","- Train loss : 1.625\n","- Eval metrics : acc: 80.696 ; loss: 1.120\n","- So far best epoch: 74, best acc: 82.486\n","Epoch 79/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.10it/s, loss=1.650]\n","- Train loss : 1.650\n","- Eval metrics : acc: 81.952 ; loss: 1.009\n","- So far best epoch: 74, best acc: 82.486\n","Epoch 80/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.15it/s, loss=1.641]\n","- Train loss : 1.641\n","- Eval metrics : acc: 81.893 ; loss: 1.040\n","- So far best epoch: 74, best acc: 82.486\n","Epoch 81/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.58it/s, loss=1.636]\n","- Train loss : 1.636\n","- Eval metrics : acc: 81.151 ; loss: 1.091\n","- So far best epoch: 74, best acc: 82.486\n","Epoch 82/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.64it/s, loss=1.612]\n","- Train loss : 1.612\n","- Eval metrics : acc: 80.726 ; loss: 1.099\n","- So far best epoch: 74, best acc: 82.486\n","Epoch 83/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.33it/s, loss=1.596]\n","- Train loss : 1.596\n","- Eval metrics : acc: 81.438 ; loss: 1.103\n","- So far best epoch: 74, best acc: 82.486\n","Epoch 84/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.49it/s, loss=1.632]\n","- Train loss : 1.632\n","- Eval metrics : acc: 81.665 ; loss: 1.040\n","- So far best epoch: 74, best acc: 82.486\n","Epoch 85/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.66it/s, loss=1.581]\n","- Train loss : 1.581\n","- Eval metrics : acc: 81.596 ; loss: 1.056\n","- So far best epoch: 74, best acc: 82.486\n","Epoch 86/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.73it/s, loss=1.607]\n","- Train loss : 1.607\n","- Eval metrics : acc: 80.706 ; loss: 1.155\n","- So far best epoch: 74, best acc: 82.486\n","Epoch 87/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.72it/s, loss=1.590]\n","- Train loss : 1.590\n","- Eval metrics : acc: 81.507 ; loss: 1.068\n","- So far best epoch: 74, best acc: 82.486\n","Epoch 88/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.37it/s, loss=1.585]\n","- Train loss : 1.585\n","- Eval metrics : acc: 80.904 ; loss: 1.169\n","- So far best epoch: 74, best acc: 82.486\n","Epoch 89/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.97it/s, loss=1.549]\n","- Train loss : 1.549\n","- Eval metrics : acc: 82.051 ; loss: 1.058\n","- So far best epoch: 74, best acc: 82.486\n","Epoch 90/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.58it/s, loss=1.543]\n","- Train loss : 1.543\n","- Eval metrics : acc: 81.576 ; loss: 1.048\n","- So far best epoch: 74, best acc: 82.486\n","Epoch 91/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.72it/s, loss=1.537]\n","- Train loss : 1.537\n","- Eval metrics : acc: 81.339 ; loss: 1.122\n","- So far best epoch: 74, best acc: 82.486\n","Epoch 92/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.36it/s, loss=1.525]\n","- Train loss : 1.525\n","- Eval metrics : acc: 82.743 ; loss: 1.003\n","- New best model \n","- So far best epoch: 92, best acc: 82.743\n","Epoch 93/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.42it/s, loss=1.564]\n","- Train loss : 1.564\n","- Eval metrics : acc: 82.051 ; loss: 1.031\n","- So far best epoch: 92, best acc: 82.743\n","Epoch 94/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 60.76it/s, loss=1.518]\n","- Train loss : 1.518\n","- Eval metrics : acc: 81.220 ; loss: 1.067\n","- So far best epoch: 92, best acc: 82.743\n","Epoch 95/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.29it/s, loss=1.522]\n","- Train loss : 1.522\n","- Eval metrics : acc: 81.477 ; loss: 1.107\n","- So far best epoch: 92, best acc: 82.743\n","Epoch 96/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.03it/s, loss=1.509]\n","- Train loss : 1.509\n","- Eval metrics : acc: 81.784 ; loss: 1.017\n","- So far best epoch: 92, best acc: 82.743\n","Epoch 97/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.50it/s, loss=1.529]\n","- Train loss : 1.529\n","- Eval metrics : acc: 82.288 ; loss: 1.068\n","- So far best epoch: 92, best acc: 82.743\n","Epoch 98/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.16it/s, loss=1.496]\n","- Train loss : 1.496\n","- Eval metrics : acc: 81.398 ; loss: 1.067\n","- So far best epoch: 92, best acc: 82.743\n","Epoch 99/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.26it/s, loss=1.457]\n","- Train loss : 1.457\n","- Eval metrics : acc: 81.636 ; loss: 1.070\n","- So far best epoch: 92, best acc: 82.743\n","Epoch 100/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.36it/s, loss=1.458]\n","- Train loss : 1.458\n","- Eval metrics : acc: 81.735 ; loss: 1.085\n","- So far best epoch: 92, best acc: 82.743\n"]}],"source":["!python train_kd.py --save_path experiments/CIFAR10/kd_nasty_resnet18/cnn"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ajY4p9IyxlK","outputId":"4759f1b9-2f75-436e-868e-da8e79178fb0"},"outputs":[{"name":"stdout","output_type":"stream","text":["model_name:net\n","num_channels:32\n","dropout_rate:0.0\n","learning_rate:0.001\n","schedule:[999]\n","gamma:0.1\n","batch_size:128\n","num_epochs:100\n","num_workers:4\n","augmentation:1\n","cuda:True\n","dataset:cifar10\n","teacher_model:resnet18\n","teacher_resume:experiments/CIFAR10/baseline/resnet18/best_model.tar\n","temperature:4\n","alpha:0.9\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Number of class: 10\n","Create Student Model --- net\n","Create Teacher Model --- resnet18\n","- Train from scratch \n","- Load Trained teacher model from experiments/CIFAR10/baseline/resnet18/best_model.tar\n","Optimizer: Adam\n","- Teacher Model Evaluation ....\n","- Teacher Model Eval metrics : acc: 94.818 ; loss: 0.201\n","Epoch 1/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 58.92it/s, loss=6.250]\n","- Train loss : 6.250\n","- Eval metrics : acc: 64.933 ; loss: 1.179\n","- New best model \n","- So far best epoch: 1, best acc: 64.933\n","Epoch 2/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.51it/s, loss=4.656]\n","- Train loss : 4.656\n","- Eval metrics : acc: 71.123 ; loss: 0.983\n","- New best model \n","- So far best epoch: 2, best acc: 71.123\n","Epoch 3/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.11it/s, loss=4.144]\n","- Train loss : 4.144\n","- Eval metrics : acc: 74.426 ; loss: 0.862\n","- New best model \n","- So far best epoch: 3, best acc: 74.426\n","Epoch 4/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.43it/s, loss=3.836]\n","- Train loss : 3.836\n","- Eval metrics : acc: 76.266 ; loss: 0.809\n","- New best model \n","- So far best epoch: 4, best acc: 76.266\n","Epoch 5/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.73it/s, loss=3.631]\n","- Train loss : 3.631\n","- Eval metrics : acc: 77.077 ; loss: 0.780\n","- New best model \n","- So far best epoch: 5, best acc: 77.077\n","Epoch 6/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.01it/s, loss=3.467]\n","- Train loss : 3.467\n","- Eval metrics : acc: 77.136 ; loss: 0.771\n","- New best model \n","- So far best epoch: 6, best acc: 77.136\n","Epoch 7/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.07it/s, loss=3.328]\n","- Train loss : 3.328\n","- Eval metrics : acc: 79.104 ; loss: 0.723\n","- New best model \n","- So far best epoch: 7, best acc: 79.104\n","Epoch 8/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.62it/s, loss=3.229]\n","- Train loss : 3.229\n","- Eval metrics : acc: 79.223 ; loss: 0.717\n","- New best model \n","- So far best epoch: 8, best acc: 79.223\n","Epoch 9/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.05it/s, loss=3.131]\n","- Train loss : 3.131\n","- Eval metrics : acc: 80.311 ; loss: 0.670\n","- New best model \n","- So far best epoch: 9, best acc: 80.311\n","Epoch 10/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.93it/s, loss=3.019]\n","- Train loss : 3.019\n","- Eval metrics : acc: 80.548 ; loss: 0.664\n","- New best model \n","- So far best epoch: 10, best acc: 80.548\n","Epoch 11/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.02it/s, loss=2.959]\n","- Train loss : 2.959\n","- Eval metrics : acc: 81.062 ; loss: 0.655\n","- New best model \n","- So far best epoch: 11, best acc: 81.062\n","Epoch 12/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.89it/s, loss=2.896]\n","- Train loss : 2.896\n","- Eval metrics : acc: 79.984 ; loss: 0.694\n","- So far best epoch: 11, best acc: 81.062\n","Epoch 13/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.39it/s, loss=2.822]\n","- Train loss : 2.822\n","- Eval metrics : acc: 82.456 ; loss: 0.624\n","- New best model \n","- So far best epoch: 13, best acc: 82.456\n","Epoch 14/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.32it/s, loss=2.748]\n","- Train loss : 2.748\n","- Eval metrics : acc: 82.170 ; loss: 0.610\n","- So far best epoch: 13, best acc: 82.456\n","Epoch 15/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 60.10it/s, loss=2.710]\n","- Train loss : 2.710\n","- Eval metrics : acc: 82.704 ; loss: 0.582\n","- New best model \n","- So far best epoch: 15, best acc: 82.704\n","Epoch 16/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.45it/s, loss=2.659]\n","- Train loss : 2.659\n","- Eval metrics : acc: 82.842 ; loss: 0.586\n","- New best model \n","- So far best epoch: 16, best acc: 82.842\n","Epoch 17/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.05it/s, loss=2.619]\n","- Train loss : 2.619\n","- Eval metrics : acc: 83.119 ; loss: 0.592\n","- New best model \n","- So far best epoch: 17, best acc: 83.119\n","Epoch 18/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.64it/s, loss=2.559]\n","- Train loss : 2.559\n","- Eval metrics : acc: 83.614 ; loss: 0.560\n","- New best model \n","- So far best epoch: 18, best acc: 83.614\n","Epoch 19/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.33it/s, loss=2.519]\n","- Train loss : 2.519\n","- Eval metrics : acc: 82.714 ; loss: 0.596\n","- So far best epoch: 18, best acc: 83.614\n","Epoch 20/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.48it/s, loss=2.496]\n","- Train loss : 2.496\n","- Eval metrics : acc: 84.405 ; loss: 0.547\n","- New best model \n","- So far best epoch: 20, best acc: 84.405\n","Epoch 21/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.59it/s, loss=2.442]\n","- Train loss : 2.442\n","- Eval metrics : acc: 83.594 ; loss: 0.574\n","- So far best epoch: 20, best acc: 84.405\n","Epoch 22/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.82it/s, loss=2.422]\n","- Train loss : 2.422\n","- Eval metrics : acc: 83.970 ; loss: 0.542\n","- So far best epoch: 20, best acc: 84.405\n","Epoch 23/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.84it/s, loss=2.376]\n","- Train loss : 2.376\n","- Eval metrics : acc: 84.217 ; loss: 0.555\n","- So far best epoch: 20, best acc: 84.405\n","Epoch 24/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.46it/s, loss=2.354]\n","- Train loss : 2.354\n","- Eval metrics : acc: 84.335 ; loss: 0.554\n","- So far best epoch: 20, best acc: 84.405\n","Epoch 25/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.44it/s, loss=2.320]\n","- Train loss : 2.320\n","- Eval metrics : acc: 84.701 ; loss: 0.523\n","- New best model \n","- So far best epoch: 25, best acc: 84.701\n","Epoch 26/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.96it/s, loss=2.314]\n","- Train loss : 2.314\n","- Eval metrics : acc: 84.662 ; loss: 0.523\n","- So far best epoch: 25, best acc: 84.701\n","Epoch 27/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.46it/s, loss=2.267]\n","- Train loss : 2.267\n","- Eval metrics : acc: 84.869 ; loss: 0.537\n","- New best model \n","- So far best epoch: 27, best acc: 84.869\n","Epoch 28/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.84it/s, loss=2.251]\n","- Train loss : 2.251\n","- Eval metrics : acc: 85.295 ; loss: 0.523\n","- New best model \n","- So far best epoch: 28, best acc: 85.295\n","Epoch 29/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.62it/s, loss=2.234]\n","- Train loss : 2.234\n","- Eval metrics : acc: 83.712 ; loss: 0.559\n","- So far best epoch: 28, best acc: 85.295\n","Epoch 30/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.61it/s, loss=2.190]\n","- Train loss : 2.190\n","- Eval metrics : acc: 84.266 ; loss: 0.544\n","- So far best epoch: 28, best acc: 85.295\n","Epoch 31/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.37it/s, loss=2.172]\n","- Train loss : 2.172\n","- Eval metrics : acc: 85.295 ; loss: 0.511\n","- New best model \n","- So far best epoch: 31, best acc: 85.295\n","Epoch 32/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.62it/s, loss=2.157]\n","- Train loss : 2.157\n","- Eval metrics : acc: 84.988 ; loss: 0.526\n","- So far best epoch: 31, best acc: 85.295\n","Epoch 33/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.32it/s, loss=2.142]\n","- Train loss : 2.142\n","- Eval metrics : acc: 85.710 ; loss: 0.498\n","- New best model \n","- So far best epoch: 33, best acc: 85.710\n","Epoch 34/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.62it/s, loss=2.119]\n","- Train loss : 2.119\n","- Eval metrics : acc: 85.848 ; loss: 0.496\n","- New best model \n","- So far best epoch: 34, best acc: 85.848\n","Epoch 35/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.27it/s, loss=2.097]\n","- Train loss : 2.097\n","- Eval metrics : acc: 85.611 ; loss: 0.493\n","- So far best epoch: 34, best acc: 85.848\n","Epoch 36/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.59it/s, loss=2.083]\n","- Train loss : 2.083\n","- Eval metrics : acc: 85.710 ; loss: 0.493\n","- So far best epoch: 34, best acc: 85.848\n","Epoch 37/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.58it/s, loss=2.075]\n","- Train loss : 2.075\n","- Eval metrics : acc: 85.117 ; loss: 0.518\n","- So far best epoch: 34, best acc: 85.848\n","Epoch 38/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.57it/s, loss=2.044]\n","- Train loss : 2.044\n","- Eval metrics : acc: 85.611 ; loss: 0.504\n","- So far best epoch: 34, best acc: 85.848\n","Epoch 39/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.45it/s, loss=2.018]\n","- Train loss : 2.018\n","- Eval metrics : acc: 85.848 ; loss: 0.504\n","- New best model \n","- So far best epoch: 39, best acc: 85.848\n","Epoch 40/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.30it/s, loss=2.035]\n","- Train loss : 2.035\n","- Eval metrics : acc: 85.819 ; loss: 0.499\n","- So far best epoch: 39, best acc: 85.848\n","Epoch 41/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.19it/s, loss=2.014]\n","- Train loss : 2.014\n","- Eval metrics : acc: 85.374 ; loss: 0.511\n","- So far best epoch: 39, best acc: 85.848\n","Epoch 42/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.72it/s, loss=1.985]\n","- Train loss : 1.985\n","- Eval metrics : acc: 85.038 ; loss: 0.525\n","- So far best epoch: 39, best acc: 85.848\n","Epoch 43/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.65it/s, loss=1.978]\n","- Train loss : 1.978\n","- Eval metrics : acc: 85.750 ; loss: 0.488\n","- So far best epoch: 39, best acc: 85.848\n","Epoch 44/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.36it/s, loss=1.954]\n","- Train loss : 1.954\n","- Eval metrics : acc: 86.195 ; loss: 0.482\n","- New best model \n","- So far best epoch: 44, best acc: 86.195\n","Epoch 45/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.59it/s, loss=1.949]\n","- Train loss : 1.949\n","- Eval metrics : acc: 86.323 ; loss: 0.480\n","- New best model \n","- So far best epoch: 45, best acc: 86.323\n","Epoch 46/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 60.67it/s, loss=1.928]\n","- Train loss : 1.928\n","- Eval metrics : acc: 85.710 ; loss: 0.496\n","- So far best epoch: 45, best acc: 86.323\n","Epoch 47/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.74it/s, loss=1.914]\n","- Train loss : 1.914\n","- Eval metrics : acc: 86.392 ; loss: 0.487\n","- New best model \n","- So far best epoch: 47, best acc: 86.392\n","Epoch 48/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.43it/s, loss=1.904]\n","- Train loss : 1.904\n","- Eval metrics : acc: 86.303 ; loss: 0.484\n","- So far best epoch: 47, best acc: 86.392\n","Epoch 49/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.34it/s, loss=1.896]\n","- Train loss : 1.896\n","- Eval metrics : acc: 86.254 ; loss: 0.485\n","- So far best epoch: 47, best acc: 86.392\n","Epoch 50/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.46it/s, loss=1.883]\n","- Train loss : 1.883\n","- Eval metrics : acc: 86.402 ; loss: 0.492\n","- New best model \n","- So far best epoch: 50, best acc: 86.402\n","Epoch 51/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.21it/s, loss=1.874]\n","- Train loss : 1.874\n","- Eval metrics : acc: 86.244 ; loss: 0.497\n","- So far best epoch: 50, best acc: 86.402\n","Epoch 52/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.47it/s, loss=1.861]\n","- Train loss : 1.861\n","- Eval metrics : acc: 86.709 ; loss: 0.481\n","- New best model \n","- So far best epoch: 52, best acc: 86.709\n","Epoch 53/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.65it/s, loss=1.849]\n","- Train loss : 1.849\n","- Eval metrics : acc: 86.472 ; loss: 0.476\n","- So far best epoch: 52, best acc: 86.709\n","Epoch 54/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.04it/s, loss=1.829]\n","- Train loss : 1.829\n","- Eval metrics : acc: 86.511 ; loss: 0.488\n","- So far best epoch: 52, best acc: 86.709\n","Epoch 55/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.51it/s, loss=1.826]\n","- Train loss : 1.826\n","- Eval metrics : acc: 86.383 ; loss: 0.497\n","- So far best epoch: 52, best acc: 86.709\n","Epoch 56/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.88it/s, loss=1.824]\n","- Train loss : 1.824\n","- Eval metrics : acc: 86.541 ; loss: 0.481\n","- So far best epoch: 52, best acc: 86.709\n","Epoch 57/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.48it/s, loss=1.811]\n","- Train loss : 1.811\n","- Eval metrics : acc: 86.778 ; loss: 0.475\n","- New best model \n","- So far best epoch: 57, best acc: 86.778\n","Epoch 58/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.53it/s, loss=1.795]\n","- Train loss : 1.795\n","- Eval metrics : acc: 86.501 ; loss: 0.490\n","- So far best epoch: 57, best acc: 86.778\n","Epoch 59/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.99it/s, loss=1.783]\n","- Train loss : 1.783\n","- Eval metrics : acc: 87.164 ; loss: 0.469\n","- New best model \n","- So far best epoch: 59, best acc: 87.164\n","Epoch 60/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.86it/s, loss=1.782]\n","- Train loss : 1.782\n","- Eval metrics : acc: 86.659 ; loss: 0.477\n","- So far best epoch: 59, best acc: 87.164\n","Epoch 61/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.70it/s, loss=1.774]\n","- Train loss : 1.774\n","- Eval metrics : acc: 86.561 ; loss: 0.485\n","- So far best epoch: 59, best acc: 87.164\n","Epoch 62/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.50it/s, loss=1.764]\n","- Train loss : 1.764\n","- Eval metrics : acc: 86.432 ; loss: 0.473\n","- So far best epoch: 59, best acc: 87.164\n","Epoch 63/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.80it/s, loss=1.751]\n","- Train loss : 1.751\n","- Eval metrics : acc: 86.669 ; loss: 0.466\n","- So far best epoch: 59, best acc: 87.164\n","Epoch 64/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.65it/s, loss=1.742]\n","- Train loss : 1.742\n","- Eval metrics : acc: 86.917 ; loss: 0.483\n","- So far best epoch: 59, best acc: 87.164\n","Epoch 65/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.46it/s, loss=1.735]\n","- Train loss : 1.735\n","- Eval metrics : acc: 86.907 ; loss: 0.470\n","- So far best epoch: 59, best acc: 87.164\n","Epoch 66/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.79it/s, loss=1.729]\n","- Train loss : 1.729\n","- Eval metrics : acc: 86.630 ; loss: 0.470\n","- So far best epoch: 59, best acc: 87.164\n","Epoch 67/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.46it/s, loss=1.717]\n","- Train loss : 1.717\n","- Eval metrics : acc: 86.274 ; loss: 0.501\n","- So far best epoch: 59, best acc: 87.164\n","Epoch 68/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.42it/s, loss=1.724]\n","- Train loss : 1.724\n","- Eval metrics : acc: 87.381 ; loss: 0.462\n","- New best model \n","- So far best epoch: 68, best acc: 87.381\n","Epoch 69/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.46it/s, loss=1.691]\n","- Train loss : 1.691\n","- Eval metrics : acc: 86.501 ; loss: 0.469\n","- So far best epoch: 68, best acc: 87.381\n","Epoch 70/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.57it/s, loss=1.686]\n","- Train loss : 1.686\n","- Eval metrics : acc: 86.887 ; loss: 0.470\n","- So far best epoch: 68, best acc: 87.381\n","Epoch 71/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.29it/s, loss=1.695]\n","- Train loss : 1.695\n","- Eval metrics : acc: 87.391 ; loss: 0.459\n","- New best model \n","- So far best epoch: 71, best acc: 87.391\n","Epoch 72/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.80it/s, loss=1.699]\n","- Train loss : 1.699\n","- Eval metrics : acc: 85.938 ; loss: 0.505\n","- So far best epoch: 71, best acc: 87.391\n","Epoch 73/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.78it/s, loss=1.671]\n","- Train loss : 1.671\n","- Eval metrics : acc: 87.065 ; loss: 0.462\n","- So far best epoch: 71, best acc: 87.391\n","Epoch 74/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.80it/s, loss=1.663]\n","- Train loss : 1.663\n","- Eval metrics : acc: 86.511 ; loss: 0.493\n","- So far best epoch: 71, best acc: 87.391\n","Epoch 75/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.66it/s, loss=1.651]\n","- Train loss : 1.651\n","- Eval metrics : acc: 86.986 ; loss: 0.469\n","- So far best epoch: 71, best acc: 87.391\n","Epoch 76/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.12it/s, loss=1.656]\n","- Train loss : 1.656\n","- Eval metrics : acc: 86.531 ; loss: 0.483\n","- So far best epoch: 71, best acc: 87.391\n","Epoch 77/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 60.56it/s, loss=1.659]\n","- Train loss : 1.659\n","- Eval metrics : acc: 86.917 ; loss: 0.474\n","- So far best epoch: 71, best acc: 87.391\n","Epoch 78/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.28it/s, loss=1.616]\n","- Train loss : 1.616\n","- Eval metrics : acc: 87.104 ; loss: 0.463\n","- So far best epoch: 71, best acc: 87.391\n","Epoch 79/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.44it/s, loss=1.629]\n","- Train loss : 1.629\n","- Eval metrics : acc: 86.501 ; loss: 0.480\n","- So far best epoch: 71, best acc: 87.391\n","Epoch 80/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.50it/s, loss=1.629]\n","- Train loss : 1.629\n","- Eval metrics : acc: 87.006 ; loss: 0.472\n","- So far best epoch: 71, best acc: 87.391\n","Epoch 81/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.62it/s, loss=1.618]\n","- Train loss : 1.618\n","- Eval metrics : acc: 86.897 ; loss: 0.479\n","- So far best epoch: 71, best acc: 87.391\n","Epoch 82/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.50it/s, loss=1.608]\n","- Train loss : 1.608\n","- Eval metrics : acc: 87.075 ; loss: 0.466\n","- So far best epoch: 71, best acc: 87.391\n","Epoch 83/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.86it/s, loss=1.611]\n","- Train loss : 1.611\n","- Eval metrics : acc: 87.391 ; loss: 0.455\n","- New best model \n","- So far best epoch: 83, best acc: 87.391\n","Epoch 84/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.84it/s, loss=1.597]\n","- Train loss : 1.597\n","- Eval metrics : acc: 87.095 ; loss: 0.469\n","- So far best epoch: 83, best acc: 87.391\n","Epoch 85/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.35it/s, loss=1.601]\n","- Train loss : 1.601\n","- Eval metrics : acc: 87.144 ; loss: 0.468\n","- So far best epoch: 83, best acc: 87.391\n","Epoch 86/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.31it/s, loss=1.584]\n","- Train loss : 1.584\n","- Eval metrics : acc: 87.114 ; loss: 0.463\n","- So far best epoch: 83, best acc: 87.391\n","Epoch 87/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.86it/s, loss=1.569]\n","- Train loss : 1.569\n","- Eval metrics : acc: 87.164 ; loss: 0.470\n","- So far best epoch: 83, best acc: 87.391\n","Epoch 88/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.55it/s, loss=1.575]\n","- Train loss : 1.575\n","- Eval metrics : acc: 86.996 ; loss: 0.475\n","- So far best epoch: 83, best acc: 87.391\n","Epoch 89/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.75it/s, loss=1.568]\n","- Train loss : 1.568\n","- Eval metrics : acc: 86.630 ; loss: 0.469\n","- So far best epoch: 83, best acc: 87.391\n","Epoch 90/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.48it/s, loss=1.554]\n","- Train loss : 1.554\n","- Eval metrics : acc: 87.006 ; loss: 0.469\n","- So far best epoch: 83, best acc: 87.391\n","Epoch 91/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.51it/s, loss=1.542]\n","- Train loss : 1.542\n","- Eval metrics : acc: 87.668 ; loss: 0.453\n","- New best model \n","- So far best epoch: 91, best acc: 87.668\n","Epoch 92/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.00it/s, loss=1.552]\n","- Train loss : 1.552\n","- Eval metrics : acc: 87.431 ; loss: 0.459\n","- So far best epoch: 91, best acc: 87.668\n","Epoch 93/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.28it/s, loss=1.550]\n","- Train loss : 1.550\n","- Eval metrics : acc: 87.184 ; loss: 0.465\n","- So far best epoch: 91, best acc: 87.668\n","Epoch 94/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.46it/s, loss=1.530]\n","- Train loss : 1.530\n","- Eval metrics : acc: 87.085 ; loss: 0.479\n","- So far best epoch: 91, best acc: 87.668\n","Epoch 95/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.47it/s, loss=1.549]\n","- Train loss : 1.549\n","- Eval metrics : acc: 87.342 ; loss: 0.477\n","- So far best epoch: 91, best acc: 87.668\n","Epoch 96/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.68it/s, loss=1.521]\n","- Train loss : 1.521\n","- Eval metrics : acc: 86.729 ; loss: 0.493\n","- So far best epoch: 91, best acc: 87.668\n","Epoch 97/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.59it/s, loss=1.516]\n","- Train loss : 1.516\n","- Eval metrics : acc: 86.778 ; loss: 0.489\n","- So far best epoch: 91, best acc: 87.668\n","Epoch 98/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.92it/s, loss=1.522]\n","- Train loss : 1.522\n","- Eval metrics : acc: 87.332 ; loss: 0.463\n","- So far best epoch: 91, best acc: 87.668\n","Epoch 99/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 61.75it/s, loss=1.505]\n","- Train loss : 1.505\n","- Eval metrics : acc: 87.589 ; loss: 0.464\n","- So far best epoch: 91, best acc: 87.668\n","Epoch 100/100\n","Learning Rate 0.001\n","100% 391/391 [00:06<00:00, 62.36it/s, loss=1.502]\n","- Train loss : 1.502\n","- Eval metrics : acc: 86.996 ; loss: 0.471\n","- So far best epoch: 91, best acc: 87.668\n"]}],"source":["!python train_kd.py --save_path experiments/CIFAR10/kd_normal_resnet18/cnn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rox7oA-ay1lb"},"outputs":[],"source":["from google.colab import runtime\n","runtime.unassign()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}